{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Autoencoder.__init__() missing 1 required positional argument: 'input_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/experiment_MSELoss_SGD_lr_0.001_5/model_399.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path))\n\u001b[1;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Autoencoder.__init__() missing 1 required positional argument: 'input_size'"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "\n",
    "model_path = 'output/experiment_MSELoss_SGD_lr_0.001_5/model_399.pth'\n",
    "\n",
    "model = Autoencoder(train.values.shape[1])\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>id</th>\n",
       "      <th>train_test</th>\n",
       "      <th>status_type_id</th>\n",
       "      <th>sensor_0_avg</th>\n",
       "      <th>sensor_1_avg</th>\n",
       "      <th>sensor_2_avg</th>\n",
       "      <th>wind_speed_3_avg</th>\n",
       "      <th>wind_speed_4_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>sensor_52_avg</th>\n",
       "      <th>sensor_52_max</th>\n",
       "      <th>sensor_52_min</th>\n",
       "      <th>sensor_52_std</th>\n",
       "      <th>sensor_53_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-22 06:50:00</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>161.3</td>\n",
       "      <td>156.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-682.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-22 07:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>172.3</td>\n",
       "      <td>167.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-996.0</td>\n",
       "      <td>-972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-22 07:10:00</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-542.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-849.0</td>\n",
       "      <td>-542.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-22 07:20:00</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>168.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-327.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-781.0</td>\n",
       "      <td>-327.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-22 07:30:00</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>155.4</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-748.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_stamp  asset_id  id train_test  status_type_id  sensor_0_avg  \\\n",
       "0  2022-05-22 06:50:00        11   0      train               5          18.0   \n",
       "1  2022-05-22 07:00:00        11   1      train               5          18.0   \n",
       "2  2022-05-22 07:10:00        11   2      train               5          18.0   \n",
       "3  2022-05-22 07:20:00        11   3      train               5          18.0   \n",
       "4  2022-05-22 07:30:00        11   4      train               5          18.0   \n",
       "\n",
       "   sensor_1_avg  sensor_2_avg  wind_speed_3_avg  wind_speed_4_avg  ...  \\\n",
       "0         161.3         156.2               2.4               2.4  ...   \n",
       "1         172.3         167.1               2.8               2.8  ...   \n",
       "2         173.0          41.0               3.1               3.1  ...   \n",
       "3         168.4           5.6               2.4               2.4  ...   \n",
       "4         155.4         -18.6               2.3               2.3  ...   \n",
       "\n",
       "   sensor_47  sensor_48  sensor_49  sensor_50  sensor_51  sensor_52_avg  \\\n",
       "0     -130.0        0.0        0.0     -682.0     -130.0            0.0   \n",
       "1     -972.0        0.0        0.0     -996.0     -972.0            0.0   \n",
       "2     -542.0        0.0        0.0     -849.0     -542.0            2.0   \n",
       "3     -327.0        0.0        0.0     -781.0     -327.0            1.5   \n",
       "4     -253.0        0.0        0.0     -748.0     -253.0            1.2   \n",
       "\n",
       "   sensor_52_max  sensor_52_min  sensor_52_std  sensor_53_avg  \n",
       "0            0.0            0.0            0.0           19.0  \n",
       "1            0.0            0.0            0.0           19.0  \n",
       "2            2.2            0.0            0.3           20.0  \n",
       "3            2.1            0.0            0.5           20.0  \n",
       "4            1.9            0.0            0.8           20.0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training and validation data from datasets\n",
    "# Files data/care_to_compare/Wind Farm A/datasets/25\n",
    "# Files data/care_to_compare/Wind Farm A/datasets/69\n",
    "# Files data/care_to_compare/Wind Farm A/datasets/13\n",
    "\n",
    "# Load csv file\n",
    "df_25 = pd.read_csv('../../data/care_to_compare/Wind Farm A/datasets/25.csv', delimiter=';')\n",
    "df_69 = pd.read_csv('../../data/care_to_compare/Wind Farm A/datasets/69.csv', delimiter=';')\n",
    "df_13 = pd.read_csv('../../data/care_to_compare/Wind Farm A/datasets/13.csv', delimiter=';')\n",
    "\n",
    "# Combine dataframes\n",
    "#df = pd.concat([df_25, df_69, df_13])\n",
    "df = df_25\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all train data (all rows where 'train_terst' column is 'train')\n",
    "train_data = df[df['train_test'] == 'train']\n",
    "test_data = df[df['train_test'] == 'prediction']\n",
    "\n",
    "# Remove the first 5 columns (not needed for training)\n",
    "train = train_data.iloc[:, 5:]\n",
    "test = test_data.iloc[:, 5:]\n",
    "\n",
    "# Remove column that contains 'sensor_1', 'sensor_2', 'sensor_5', 'sensor_42'\n",
    "train = train.drop(columns=['sensor_0_avg', 'sensor_1_avg', 'sensor_2_avg', 'wind_speed_4_avg', 'sensor_5_avg', 'sensor_5_max', 'sensor_5_min', 'sensor_42_avg'])\n",
    "test = test.drop(columns=['sensor_0_avg', 'sensor_1_avg', 'sensor_2_avg', 'wind_speed_4_avg', 'sensor_5_avg', 'sensor_5_max', 'sensor_5_min', 'sensor_42_avg'])\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "# data_normalized = scaler.fit_transform(train.values)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data_normalized = scaler.fit_transform(train.values)\n",
    "test_data_normalized = scaler.fit_transform(test.values)\n",
    "\n",
    "# Create tensors  \n",
    "train_data_normalized = torch.tensor(train_data_normalized, dtype=torch.float32)\n",
    "test_data_normalized = torch.tensor(test_data_normalized, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 128\n",
    "dataset = TensorDataset(train_data_normalized)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m       losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m predictions, losses\n\u001b[0;32m---> 19\u001b[0m _, losses \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_normalized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m sns\u001b[38;5;241m.\u001b[39mdisplot(losses, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m);\n",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m      6\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mL1Loss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m seq_true \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     10\u001b[0m     seq_true \u001b[38;5;241m=\u001b[39m seq_true\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# Test the model on the test data\n",
    "# From: https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/manuscript/06.time-series-anomaly-ecg.md\n",
    "\n",
    "def predict(model, dataset):\n",
    "  predictions, losses = [], []\n",
    "  criterion = torch.nn.L1Loss(reduction='sum').to(device)\n",
    "  with torch.no_grad():\n",
    "    model = model.eval()\n",
    "    for seq_true in dataset:\n",
    "      seq_true = seq_true.to(device)\n",
    "      seq_pred = model(seq_true)\n",
    "\n",
    "      loss = criterion(seq_pred, seq_true)\n",
    "\n",
    "      predictions.append(seq_pred.cpu().numpy().flatten())\n",
    "      losses.append(loss.item())\n",
    "  return predictions, losses\n",
    "\n",
    "_, losses = predict(model, train_data_normalized)\n",
    "\n",
    "sns.displot(losses, bins=50, kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 13\n",
    "\n",
    "predictions, pred_losses = predict(model, test_data_normalized)\n",
    "sns.displot(pred_losses, bins=50, kde=True);\n",
    "\n",
    "correct = sum(l <= THRESHOLD for l in pred_losses)\n",
    "print(f'Correct normal predictions: {correct}/{len(test_data_normalized)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anamoly dataset\n",
    "df_68 = pd.read_csv('../../data/care_to_compare/Wind Farm A/datasets/68.csv', delimiter=';')\n",
    "\n",
    "anamoly_data = df_68.iloc[:, 5:]\n",
    "anamoly_data = anamoly_data.drop(columns=['sensor_0_avg', 'sensor_1_avg', 'sensor_2_avg', 'wind_speed_4_avg', 'sensor_5_avg', 'sensor_5_max', 'sensor_5_min', 'sensor_42_avg'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "anamoly_data_normalized = scaler.fit_transform(anamoly_data.values)\n",
    "anamoly_data_normalized = torch.tensor(anamoly_data_normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, pred_losses = predict(model, anamoly_data_normalized)\n",
    "\n",
    "# Plot a time series of the prediction losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pred_losses, label='Loss')\n",
    "plt.axhline(THRESHOLD, color='r', label='Threshold')\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "sns.displot(pred_losses, bins=50, kde=True);\n",
    "\n",
    "correct = sum(l > THRESHOLD for l in pred_losses)\n",
    "print(f'Correct anomaly predictions: {correct}/{len(anamoly_data_normalized)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
