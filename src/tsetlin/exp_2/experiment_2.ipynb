{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "\n",
    "from tmu.models.classification.vanilla_classifier import TMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_sensors = [\"sensor_0_avg\", \"sensor_1_avg\", \"power_2_avg\", \"sensor_3_avg\", \"sensor_4_avg\", \"sensor_9_avg\", \"power_5_avg\", \"power_6_avg\", \"sensor_7_avg\", \"sensor_8_avg\", \"sensor_10_avg\", \"sensor_11_avg\"]\n",
    "\n",
    "exclude_columns = [\"time_stamp\", \"asset_id\", \"id\", \"status_type_id\"], \n",
    "\n",
    "def load_df_and_annotate_anomalies(farm, dataset_id):\n",
    "    path = f\"../../../data/care_to_compare/Wind Farm {farm}/datasets/{dataset_id}.csv\"\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "    \n",
    "    # If ['status_type_id'] is 0 or 2, then 0, else 1\n",
    "    df['label'] = df['status_type_id'].apply(lambda x: 0 if x in [0, 2] else 1)\n",
    "    \n",
    "    # Include all columns except for the ones in exclude_columns\n",
    "    df = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 44510 0s and 8050 1s\n",
      "Test data: 1188 0s and 184 1s\n",
      "Index(['time_stamp', 'asset_id', 'id', 'status_type_id', 'sensor_0_avg',\n",
      "       'sensor_0_max', 'sensor_0_min', 'sensor_0_std', 'sensor_1_avg',\n",
      "       'sensor_1_max',\n",
      "       ...\n",
      "       'wind_speed_236_min', 'wind_speed_236_std', 'wind_speed_235_avg',\n",
      "       'wind_speed_235_max', 'wind_speed_235_min', 'wind_speed_235_std',\n",
      "       'wind_speed_237_avg', 'wind_speed_237_max', 'wind_speed_237_min',\n",
      "       'wind_speed_237_std'],\n",
      "      dtype='object', length=956)\n"
     ]
    }
   ],
   "source": [
    "# Load all required data for training\n",
    "\n",
    "# 68;anomaly;2015-07-29 13:20:00;52063;2015-08-12 13:10:00;54076;Transformer failure\n",
    "\n",
    "# Load csv file\n",
    "df = pd.concat([\n",
    "    #load_df_and_annotate_anomalies('C', 55), \n",
    "    load_df_and_annotate_anomalies('C', 81), \n",
    "    #load_df_and_annotate_anomalies('C', 8),\n",
    "    #load_df_and_annotate_anomalies('C', 85)\n",
    "])\n",
    "# Sensors to use\n",
    "\n",
    "train_data = df[df['train_test'] == 'train']\n",
    "test_data = df[df['train_test'] == 'prediction']\n",
    "\n",
    "X_train = train_data.drop(columns=['label', 'train_test'])\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data.drop(columns=['label', 'train_test'])\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Print number of 0s and 1s in the label sets\n",
    "train_0s = np.count_nonzero(y_train == 0)\n",
    "train_1s = np.count_nonzero(y_train == 1)\n",
    "\n",
    "print(f\"Train data: {train_0s} 0s and {train_1s} 1s\")\n",
    "\n",
    "test_0s = np.count_nonzero(y_test == 0)\n",
    "test_1s = np.count_nonzero(y_test == 1)\n",
    "\n",
    "print(f\"Test data: {test_0s} 0s and {test_1s} 1s\")\n",
    "\n",
    "# PRint column names\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns where the value is not a number\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_train = X_train.dropna(axis=1)\n",
    "\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52560 9550\n"
     ]
    }
   ],
   "source": [
    "def convert_to_10bit_integers(df):\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "\n",
    "        # Edge case wher all values are 0\n",
    "        if min_val == max_val:\n",
    "            normalized_df[col] = 0\n",
    "        else:\n",
    "            normalized_df[col] = ((df[col] - min_val) / (max_val - min_val) * 1023)\n",
    "\n",
    "    # Convert the normalized values to integers\n",
    "    int_df = normalized_df.astype(int)\n",
    "    \n",
    "    # Flatten each row into an array of 10-bit integers\n",
    "    int_arrays = int_df.apply(lambda row: row.values.flatten(), axis=1).tolist()\n",
    "    \n",
    "    # Represent each cell as a 10-bit integer string\n",
    "    bin_arrays = [[f\"{cell:010b}\" for cell in row] for row in int_arrays]\n",
    "\n",
    "    # Split each 10-bit integer string into individual integers for each row\n",
    "    # preserve the columns of bin_arrays\n",
    "    bin_int_arrays = [[int(cell) for cell in list(''.join(row))] for row in bin_arrays]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    int_arrays = np.array(bin_int_arrays)\n",
    "\n",
    "    return int_arrays\n",
    "\n",
    "# Example usage\n",
    "X_train_binarized = convert_to_10bit_integers(X_train).astype(np.uint32)\n",
    "X_test_binarized = convert_to_10bit_integers(X_test).astype(np.uint32)\n",
    "\n",
    "y_train_binarized = y_train.values.astype(np.uint32)\n",
    "y_test_binarized = y_test.values.astype(np.uint32)\n",
    "\n",
    "# Print dimensions of the integer arrays\n",
    "print(len(X_train_binarized), len(X_train_binarized[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52560, 9550)\n",
      "(52560,)\n",
      "(1372, 9550)\n",
      "(1372,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_binarized.shape)\n",
    "print(y_train_binarized.shape)\n",
    "\n",
    "print(X_test_binarized.shape)    \n",
    "print(y_test_binarized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[0;32m      5\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X[i]]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y[i]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mwrite_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_binarized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_binarized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_train_exp_1.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m write_to_file(X_test_binarized, y_test_binarized, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_test_exp_1.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m, in \u001b[0;36mwrite_to_file\u001b[1;34m(X, y, filename)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[1;32m----> 5\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Print each row into a file data.txt\n",
    "def write_to_file(X, y, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for i in range(len(X)):\n",
    "            f.write(\" \".join([str(x) for x in X[i]]) + \" \" + str(y[i]) + \"\\n\")\n",
    "\n",
    "write_to_file(X_train_binarized, y_train_binarized, \"data_train_exp_1.txt\")\n",
    "write_to_file(X_test_binarized, y_test_binarized, \"data_test_exp_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_model(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running <class 'tmu.models.classification.vanilla_classifier.TMClassifier'> for 10 epochs\n",
      "Finished fitting\n",
      "Predicted 0s: 1142, Predicted 1s: 230\n",
      "Epoch: 1, Accuracy: 96.64723\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1158, Predicted 1s: 214\n",
      "Epoch: 2, Accuracy: 97.81341\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1155, Predicted 1s: 217\n",
      "Epoch: 3, Accuracy: 97.59475\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 4, Accuracy: 98.54227\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 5, Accuracy: 98.54227\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 6, Accuracy: 98.54227\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 7, Accuracy: 98.54227\n",
      "Finished fitting\n",
      "Predicted 0s: 1169, Predicted 1s: 203\n",
      "Epoch: 8, Accuracy: 98.61516\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1169, Predicted 1s: 203\n",
      "Epoch: 9, Accuracy: 98.61516\n",
      "Finished fitting\n",
      "Predicted 0s: 1169, Predicted 1s: 203\n",
      "Epoch: 10, Accuracy: 98.61516\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "tm = TMClassifier(\n",
    "    number_of_clauses=1000,\n",
    "    T=1000,\n",
    "    s=10.0,\n",
    "    max_included_literals=32,\n",
    "    weighted_clauses=True,\n",
    "    platform=\"CPU\",\n",
    "    batch_size=1000,\n",
    ")\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "print(f\"Running {TMClassifier} for {epochs} epochs\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tm.fit(X_train_binarized, y_train_binarized)\n",
    "\n",
    "    print(\"Finished fitting\")\n",
    "    \n",
    "    pred = tm.predict(X_test_binarized)\n",
    "\n",
    "    pred_0s = np.count_nonzero(pred == 0)\n",
    "    pred_1s = np.count_nonzero(pred == 1)\n",
    "\n",
    "    print(f\"Predicted 0s: {pred_0s}, Predicted 1s: {pred_1s}\")\n",
    "  \n",
    "    result = 100* (pred == y_test_binarized).mean()\n",
    "\n",
    "    # Print every 20 epochs\n",
    "    #if (epoch + 1) % 20 == 0:\n",
    "    print(f\"Epoch: {epoch + 1}, Accuracy: {result:.5f}\")\n",
    "\n",
    "    if result > best_accuracy:\n",
    "        best_accuracy = result\n",
    "\n",
    "        print(\"Saving model\")\n",
    "        save_model(tm, \"best.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARE score evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392 9550\n",
      "(8392, 9550)\n",
      "Evaluation data: 8051 0s and 341 1s\n"
     ]
    }
   ],
   "source": [
    "# Filter out all non\n",
    "eval_df = pd.concat([\n",
    "    load_df_and_annotate_anomalies('C', 55), \n",
    "    load_df_and_annotate_anomalies('C', 81), \n",
    "    load_df_and_annotate_anomalies('C', 8),\n",
    "    load_df_and_annotate_anomalies('C', 85)\n",
    "])\n",
    "\n",
    "eval_data = eval_df[eval_df['train_test'] == 'prediction']\n",
    "\n",
    "X_eval_data = eval_data.drop(columns=['label', 'train_test'])\n",
    "y_eval_data = eval_data['label']\n",
    "\n",
    "# Remove all columns where the value is not a number\n",
    "X_eval_data = X_eval_data.apply(pd.to_numeric, errors='coerce')\n",
    "X_eval_data = X_eval_data.dropna(axis=1)\n",
    "\n",
    "X_eval = convert_to_10bit_integers(X_eval_data).astype(np.uint32)\n",
    "y_eval = y_eval_data.values.astype(np.uint32)\n",
    "\n",
    "# Print dimensions of the integer arrays\n",
    "print(len(X_eval), len(X_eval[0]))\n",
    "\n",
    "# Print the size of the evaluation data\n",
    "print(X_eval.shape)\n",
    "\n",
    "# Print the number of 0s and 1s in the evaluation data\n",
    "eval_0s = np.count_nonzero(y_eval == 0)\n",
    "eval_1s = np.count_nonzero(y_eval == 1)\n",
    "\n",
    "print(f\"Evaluation data: {eval_0s} 0s and {eval_1s} 1s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.72593\n",
      "Positives: 341\n",
      "Negatives: 8051\n"
     ]
    }
   ],
   "source": [
    "# g = the ground truth of all data points with a normal status-ID within the prediction time frame\n",
    "g = y_eval\n",
    "\n",
    "# p = the corresponding prediction of an AD-model.\n",
    "p = tm.predict(X_eval)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * (p == g).mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "\n",
    "print(f\"Positives: {np.count_nonzero(g == 1)}\")\n",
    "print(f\"Negatives: {np.count_nonzero(g == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 341, FN = 0, FP = 23, TN = 8028, tot = 8392\n",
      "F0.5 = 3.90160\n"
     ]
    }
   ],
   "source": [
    "# Coverage\n",
    "# Detection of as many correct anomalies as possible\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "# the number of true positives based on g and p\n",
    "tp = np.sum((p == 1) & (g == 1))\n",
    "\n",
    "# the number of false negatives based on g and p\n",
    "fn = np.sum((p == 0) & (g == 1))\n",
    "\n",
    "# the number of false positives based on g and p\n",
    "fp = np.sum((p == 1) & (g == 0))\n",
    "\n",
    "tn = np.sum((p == 0) & (g == 0))\n",
    "\n",
    "Fbeta = (1 + beta**2) * tp / (1 + beta**2 * tp + beta**2 * fn + fp)\n",
    "\n",
    "print(f\"TP = {tp}, FN = {fn}, FP = {fp}, TN = {tn}, tot = {len(g)}\")\n",
    "print(f\"F{beta} = {Fbeta:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# Recognition of normal behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reliability\n",
    "# Few false alarm events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earliness\n",
    "# Detection of anomalies before fault gets critical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
