{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from tmu.models.classification.vanilla_classifier import TMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_sensors = [\"sensor_0_avg\", \"sensor_1_avg\", \"power_2_avg\", \"sensor_3_avg\", \"sensor_4_avg\", \"sensor_9_avg\", \"power_5_avg\", \"power_6_avg\", \"sensor_7_avg\", \"sensor_8_avg\", \"sensor_10_avg\", \"sensor_11_avg\"]\n",
    "\n",
    "exclude_columns = [\"time_stamp\", \"asset_id\", \"id\", \"status_type_id\"], \n",
    "\n",
    "def load_df_and_annotate_anomalies(farm, dataset_id):\n",
    "    path = f\"../../../data/care_to_compare/Wind Farm {farm}/datasets/{dataset_id}.csv\"\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "    \n",
    "    # If ['status_type_id'] is 0 or 2 (considered normal), then 0, else 1\n",
    "    df['label'] = df['status_type_id'].apply(lambda x: 0 if x in [0, 2] else 1)\n",
    "    \n",
    "    # Include all columns except for the ones in exclude_columns\n",
    "    df = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_10bit_integers(df):\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "\n",
    "        # Edge case wher all values are 0\n",
    "        if min_val == max_val:\n",
    "            normalized_df[col] = 0\n",
    "        else:\n",
    "            normalized_df[col] = ((df[col] - min_val) / (max_val - min_val) * 1023)\n",
    "\n",
    "    # Convert the normalized values to integers\n",
    "    int_df = normalized_df.astype(int)\n",
    "    \n",
    "    # Flatten each row into an array of 10-bit integers\n",
    "    int_arrays = int_df.apply(lambda row: row.values.flatten(), axis=1).tolist()\n",
    "    \n",
    "    # Represent each cell as a 10-bit integer string\n",
    "    bin_arrays = [[f\"{cell:010b}\" for cell in row] for row in int_arrays]\n",
    "\n",
    "    # Split each 10-bit integer string into individual integers for each row\n",
    "    # preserve the columns of bin_arrays\n",
    "    bin_int_arrays = [[int(cell) for cell in list(''.join(row))] for row in bin_arrays]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    int_arrays = np.array(bin_int_arrays)\n",
    "\n",
    "    return int_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "def load_model(filename) -> TMClassifier:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = load_model(\"best.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARE score evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54865 9550\n",
      "(54865, 9550)\n",
      "Evaluation data: 46335 0s (normals) and 8530 1s (anomalies)\n"
     ]
    }
   ],
   "source": [
    "# Filter out all non\n",
    "eval_df = pd.concat([\n",
    "    load_df_and_annotate_anomalies('C', 6), \n",
    "    #load_df_and_annotate_anomalies('C', 81), \n",
    "    #load_df_and_annotate_anomalies('C', 8),\n",
    "    #load_df_and_annotate_anomalies('C', 85)\n",
    "])\n",
    "\n",
    "#eval_data = eval_df[eval_df['train_test'] == 'prediction']\n",
    "eval_data = eval_df\n",
    "\n",
    "X_eval_data = eval_data.drop(columns=['label', 'train_test'])\n",
    "y_eval_data = eval_data['label']\n",
    "\n",
    "# Remove all columns where the value is not a number\n",
    "X_eval_data = X_eval_data.apply(pd.to_numeric, errors='coerce')\n",
    "X_eval_data = X_eval_data.dropna(axis=1)\n",
    "\n",
    "X_eval = convert_to_10bit_integers(X_eval_data).astype(np.uint32)\n",
    "y_eval = y_eval_data.values.astype(np.uint32)\n",
    "\n",
    "# Print dimensions of the integer arrays\n",
    "print(len(X_eval), len(X_eval[0]))\n",
    "\n",
    "# Print the size of the evaluation data\n",
    "print(X_eval.shape)\n",
    "\n",
    "# Print the number of 0s and 1s in the evaluation data\n",
    "eval_0s = np.count_nonzero(y_eval == 0)\n",
    "eval_1s = np.count_nonzero(y_eval == 1)\n",
    "\n",
    "print(f\"Evaluation data: {eval_0s} 0s (normals) and {eval_1s} 1s (anomalies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = the ground truth of all data points with a normal status-ID within the prediction time frame\n",
    "g = y_eval\n",
    "\n",
    "# p = the corresponding prediction of an AD-model.\n",
    "p = tm.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 54865\n",
      "Faulty: 0\n",
      "Accuracy: 100.00000\n",
      "Accuracy: 100.00000\n",
      "Normals: 8530\n",
      "Anomalies: 46335\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "correct = (p == g).sum()\n",
    "faulty = (p != g).sum()\n",
    "\n",
    "print(f\"Correct: {correct}\")\n",
    "print(f\"Faulty: {faulty}\")\n",
    "\n",
    "acc = correct / (correct + faulty) * 100\n",
    "\n",
    "print(f\"Accuracy: {acc:.5f}\")\n",
    "\n",
    "accuracy = 100 * (p == g).mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "\n",
    "print(f\"Normals: {np.count_nonzero(g == 1)}\")\n",
    "print(f\"Anomalies: {np.count_nonzero(g == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 8530, FN = 0, FP = 0, TN = 46335, tot = 54865\n",
      "Coverage (F) = 4.99766\n"
     ]
    }
   ],
   "source": [
    "# Coverage\n",
    "# Detection of as many correct anomalies as possible\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "# the number of true positives based on g and p\n",
    "tp = np.sum((p == 1) & (g == 1))\n",
    "\n",
    "# the number of false negatives based on g and p\n",
    "fn = np.sum((p == 0) & (g == 1))\n",
    "\n",
    "# the number of false positives based on g and p\n",
    "fp = np.sum((p == 1) & (g == 0))\n",
    "\n",
    "# the number of true negatives based on g and p\n",
    "tn = np.sum((p == 0) & (g == 0))\n",
    "\n",
    "Fbeta = (1 + beta**2) * tp / (1 + beta**2 * tp + beta**2 * fn + fp)\n",
    "\n",
    "print(f\"TP = {tp}, FN = {fn}, FP = {fp}, TN = {tn}, tot = {len(g)}\")\n",
    "print(f\"Coverage (F) = {Fbeta:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.00000\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "# Recognition of normal behavior\n",
    "\n",
    "# the number of false positives based on g and p\n",
    "fp = np.sum((p == 1) & (g == 0))\n",
    "\n",
    "# the number of true negatives based on g and p\n",
    "tn = np.sum((p == 0) & (g == 0))\n",
    "\n",
    "acc = tn / (fp + tn)\n",
    "\n",
    "print(f\"Accuracy = {acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(N, st, pt):\n",
    "    print(f\"N={N}, len(st)={len(st)}, len(pt)={len(pt)}\")\n",
    "    # Initialize crit as a list of zeros with size N + 1\n",
    "    crit = [0] * (N + 1)\n",
    "\n",
    "    # Iterate through the range 1 to N (inclusive)\n",
    "    for i in range(1, N):\n",
    "        if st[i] == 0:  # Assuming `st` is a list or array\n",
    "            if pt[i] == 1:  # Assuming `pt` is a list or array\n",
    "                crit[i] = crit[i - 1] + 1\n",
    "            else:\n",
    "                crit[i] = max(crit[i - 1] - 1, 0)\n",
    "        else:\n",
    "            crit[i] = crit[i - 1]\n",
    "\n",
    "    # Trim crit to include only elements 1 through N\n",
    "    crit = crit[1:N + 1]\n",
    "    return crit\n",
    "\n",
    "def print_results(set, p, g, crit):\n",
    "    g = [\"N\" if x == 0 else \"A\" for x in g]\n",
    "    p = [\"N\" if x == 0 else \"A\" for x in p]\n",
    "    set = [\"A\" if x == 0 else \"N\" for x in set]\n",
    "\n",
    "    df = pd.DataFrame({'set': set, 'p': p, 'g': g, 'crit': crit})\n",
    "    df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=54865, len(st)=54865, len(pt)=54865\n",
      "Max crit: 8530\n",
      "TP = 8456, FN = 74, FP = 45750, TN = 585, tot = 54865\n",
      "Reliability (EFbeta) = 0.220744097653680\n"
     ]
    }
   ],
   "source": [
    "# Reliability\n",
    "# Few false alarm events\n",
    "\n",
    "# g[i] = 0 if the status type is 0 or 2, else 1\n",
    "set = [1 if x == 0 else 0 for x in g]\n",
    "\n",
    "# Initialize a list of nulls\n",
    "crit = calc(len(set), set, p)\n",
    "\n",
    "# Print the set, p and crid in a csv file called \"results.csv\"\n",
    "print_results(set, p, g, crit)\n",
    "\n",
    "crit_max = np.max(crit)\n",
    "\n",
    "print(f\"Max crit: {crit_max}\")\n",
    "\n",
    "tc = 75\n",
    "\n",
    "# If a value is larger than the threshold, then it is an anomaly (1) else it is not (0)\n",
    "crit = [1 if c > tc else 0 for c in crit]\n",
    "crit = np.array(crit)\n",
    "\n",
    "# the number of true positives based on g and p\n",
    "tp = np.sum((crit == 1) & (g == 1))\n",
    "\n",
    "# the number of false negatives based on g and p\n",
    "fn = np.sum((crit == 0) & (g == 1))\n",
    "\n",
    "# the number of false positives based on g and p\n",
    "fp = np.sum((crit == 1) & (g == 0))\n",
    "\n",
    "# the number of true negatives based on g and p\n",
    "tn = np.sum((crit == 0) & (g == 0))\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "EFbeta = (1 + beta**2) * tp / (1 + beta**2 * tp + beta**2 * fn + fp)\n",
    "\n",
    "print(f\"TP = {tp}, FN = {fn}, FP = {fp}, TN = {tn}, tot = {len(crit)}\")\n",
    "print(f\"Reliability (EFbeta) = {EFbeta:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earliness\n",
    "# Detection of anomalies before fault gets critical.\n",
    "\n",
    "def calc_weight(sequence_of_anomalies):\n",
    "    # Normalize the positions of the elements in the sequence between 0 and 1\n",
    "    normalized_positions = np.linspace(0, 1, len(sequence_of_anomalies))\n",
    "\n",
    "    # If the normalized position is less than 0.5, then the weight is 1, else it linearly decreases to 0\n",
    "    weights = [1 if pos < 0.5 else 1 - pos for pos in normalized_positions]\n",
    "\n",
    "    return np.array(weights).astype(np.float32)\n",
    "\n",
    "anomalies = []\n",
    "\n",
    "buffer = []\n",
    "\n",
    "# Get all subsequences of anomalies of g\n",
    "for i in range(len(g)):\n",
    "\n",
    "    # If no anomaly, continue\n",
    "    if(g[i] == 0 and len(buffer) == 0):\n",
    "        continue\n",
    "\n",
    "    if(g[i] == 0 and len(buffer) > 0):\n",
    "        anomalies.append(buffer)\n",
    "        buffer = []\n",
    "        continue\n",
    "\n",
    "    buffer.append((i, g[i], p[i]))\n",
    "\n",
    "if len(buffer) > 0:\n",
    "    anomalies.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliness (WS) = 1.000000000000000\n"
     ]
    }
   ],
   "source": [
    "wspas = []\n",
    "\n",
    "for anomaly in anomalies:\n",
    "    gs = np.array([x[1] for x in anomaly]).astype(np.float32)\n",
    "    ps = np.array([x[2] for x in anomaly]).astype(np.float32)\n",
    "\n",
    "    weights = calc_weight(gs)\n",
    "\n",
    "    gsum = sum(weights * ps) / sum(weights)\n",
    "    wspas.append(gsum) \n",
    "\n",
    "WS = np.mean(wspas)\n",
    "\n",
    "print(f\"Earliness (WS) = {WS:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1915846071.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[38], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    F_final =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# CARE score calculation\n",
    "\n",
    "# Arithmetic mean of the Fbeta\n",
    "F_final = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
