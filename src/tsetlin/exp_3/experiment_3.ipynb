{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment description\n",
    "\n",
    "Train a TM Classifier to classify anomalies in CARE to comapre SCADA dataset.\n",
    "Train on a subset of the datasets, then evaluate the model on all datasets in Wind Farm C.\n",
    "\n",
    "Use the accuracy score as a simple metric to measure the performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-06 17:40:43,693 - tmu.util.cuda_profiler - WARNING - Could not import pycuda: No module named 'pycuda'\n",
      "2025-01-06 17:40:43,694 - tmu.clause_bank.clause_bank_cuda - ERROR - No module named 'pycuda'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kjell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tmu\\clause_bank\\clause_bank_cuda.py\", line 41, in <module>\n",
      "    from pycuda._driver import Device, Context\n",
      "ModuleNotFoundError: No module named 'pycuda'\n",
      "2025-01-06 17:40:43,694 - tmu.clause_bank.clause_bank_cuda - WARNING - Could not import pycuda. This indicates that it is not installed! A possible fix is to run 'pip install pycuda'. Fallback to CPU ClauseBanks.\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "\n",
    "from tmu.models.classification.vanilla_classifier import TMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = [\"time_stamp\", \"asset_id\", \"id\", \"status_type_id\"], \n",
    "\n",
    "def load_df_and_annotate_anomalies(farm, dataset_id):\n",
    "    path = f\"../../../data/care_to_compare/Wind Farm {farm}/datasets/{dataset_id}.csv\"\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "    \n",
    "    # If ['status_type_id'] is 0 or 2, then 0, else 1\n",
    "    df['label'] = df['status_type_id'].apply(lambda x: 0 if x in [0, 2] else 1)\n",
    "    \n",
    "    # Include all columns except for the ones in exclude_columns\n",
    "    df = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 44510 0s and 8050 1s\n",
      "Test data: 1188 0s and 184 1s\n"
     ]
    }
   ],
   "source": [
    "# Load all required data for training\n",
    "\n",
    "# 68;anomaly;2015-07-29 13:20:00;52063;2015-08-12 13:10:00;54076;Transformer failure\n",
    "\n",
    "# Load csv file\n",
    "df = pd.concat([\n",
    "    #load_df_and_annotate_anomalies('C', 55), \n",
    "    load_df_and_annotate_anomalies('C', 81), \n",
    "    #load_df_and_annotate_anomalies('C', 8),\n",
    "    #load_df_and_annotate_anomalies('C', 85)\n",
    "])\n",
    "# Sensors to use\n",
    "\n",
    "train_data = df[df['train_test'] == 'train']\n",
    "test_data = df[df['train_test'] == 'prediction']\n",
    "\n",
    "X_train = train_data.drop(columns=['label', 'train_test'])\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data.drop(columns=['label', 'train_test'])\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Print number of 0s and 1s in the label sets\n",
    "train_0s = np.count_nonzero(y_train == 0)\n",
    "train_1s = np.count_nonzero(y_train == 1)\n",
    "\n",
    "print(f\"Train data: {train_0s} 0s and {train_1s} 1s\")\n",
    "\n",
    "test_0s = np.count_nonzero(y_test == 0)\n",
    "test_1s = np.count_nonzero(y_test == 1)\n",
    "\n",
    "print(f\"Test data: {test_0s} 0s and {test_1s} 1s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns where the value is not a number\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_train = X_train.dropna(axis=1)\n",
    "\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52560 9550\n"
     ]
    }
   ],
   "source": [
    "def convert_to_10bit_integers(df):\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "\n",
    "        # Edge case wher all values are 0\n",
    "        if min_val == max_val:\n",
    "            normalized_df[col] = 0\n",
    "        else:\n",
    "            normalized_df[col] = ((df[col] - min_val) / (max_val - min_val) * 1023)\n",
    "\n",
    "    # Convert the normalized values to integers\n",
    "    int_df = normalized_df.astype(int)\n",
    "    \n",
    "    # Flatten each row into an array of 10-bit integers\n",
    "    int_arrays = int_df.apply(lambda row: row.values.flatten(), axis=1).tolist()\n",
    "    \n",
    "    # Represent each cell as a 10-bit integer string\n",
    "    bin_arrays = [[f\"{cell:010b}\" for cell in row] for row in int_arrays]\n",
    "\n",
    "    # Split each 10-bit integer string into individual integers for each row\n",
    "    # preserve the columns of bin_arrays\n",
    "    bin_int_arrays = [[int(cell) for cell in list(''.join(row))] for row in bin_arrays]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    int_arrays = np.array(bin_int_arrays)\n",
    "\n",
    "    return int_arrays\n",
    "\n",
    "# Example usage\n",
    "X_train_binarized = convert_to_10bit_integers(X_train).astype(np.uint32)\n",
    "X_test_binarized = convert_to_10bit_integers(X_test).astype(np.uint32)\n",
    "\n",
    "y_train_binarized = y_train.values.astype(np.uint32)\n",
    "y_test_binarized = y_test.values.astype(np.uint32)\n",
    "\n",
    "# Print dimensions of the integer arrays\n",
    "print(len(X_train_binarized), len(X_train_binarized[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52560, 9550)\n",
      "(52560,)\n",
      "(1372, 9550)\n",
      "(1372,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_binarized.shape)\n",
    "print(y_train_binarized.shape)\n",
    "print(X_test_binarized.shape)    \n",
    "print(y_test_binarized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "def save_model(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def save_accuracy(epoch, accuracy, filename):\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(f\"{epoch},{accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running <class 'tmu.models.classification.vanilla_classifier.TMClassifier'> for 10 epochs\n",
      "Finished fitting\n",
      "Predicted 0s: 1087, Predicted 1s: 285\n",
      "Epoch: 1, Accuracy: 92.63848\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1129, Predicted 1s: 243\n",
      "Epoch: 2, Accuracy: 95.69971\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1164, Predicted 1s: 208\n",
      "Epoch: 3, Accuracy: 98.25073\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1163, Predicted 1s: 209\n",
      "Epoch: 4, Accuracy: 98.17784\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 5, Accuracy: 98.54227\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1167, Predicted 1s: 205\n",
      "Epoch: 6, Accuracy: 98.46939\n",
      "Finished fitting\n",
      "Predicted 0s: 1169, Predicted 1s: 203\n",
      "Epoch: 7, Accuracy: 98.61516\n",
      "Saving model\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 8, Accuracy: 98.54227\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 9, Accuracy: 98.54227\n",
      "Finished fitting\n",
      "Predicted 0s: 1168, Predicted 1s: 204\n",
      "Epoch: 10, Accuracy: 98.54227\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "tm = TMClassifier(\n",
    "    number_of_clauses=1000,\n",
    "    T=1000,\n",
    "    s=10.0,\n",
    "    max_included_literals=32,\n",
    "    weighted_clauses=True,\n",
    "    platform=\"CPU\",\n",
    "    batch_size=1000,\n",
    ")\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "print(f\"Running {TMClassifier} for {epochs} epochs\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tm.fit(X_train_binarized, y_train_binarized)\n",
    "\n",
    "    print(\"Finished fitting\")\n",
    "    \n",
    "    pred = tm.predict(X_test_binarized)\n",
    "\n",
    "    pred_0s = np.count_nonzero(pred == 0)\n",
    "    pred_1s = np.count_nonzero(pred == 1)\n",
    "\n",
    "    print(f\"Predicted 0s: {pred_0s}, Predicted 1s: {pred_1s}\")\n",
    "  \n",
    "    result = 100* (pred == y_test_binarized).mean()\n",
    "\n",
    "    save_accuracy(epoch, result, \"accuracy.txt\")\n",
    "\n",
    "    # Print every 20 epochs\n",
    "    #if (epoch + 1) % 20 == 0:\n",
    "    print(f\"Epoch: {epoch + 1}, Accuracy: {result:.5f}\")\n",
    "\n",
    "    if result > best_accuracy:\n",
    "        best_accuracy = result\n",
    "\n",
    "        print(\"Saving model\")\n",
    "        save_model(tm, \"best.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
