{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment description\n",
    "\n",
    "The goal of this notebook is to preprocess all datasets in Wind Farm C to a binary format that can be used for training a TM Classifier."
   ],
   "id": "e85b94674bcffa5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:10:38.402384Z",
     "start_time": "2025-02-12T14:10:38.395577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "a7fa0f63187f7de2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:10:38.797493Z",
     "start_time": "2025-02-12T14:10:38.789174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exclude_columns = [\"time_stamp\", \"asset_id\", \"id\"],\n",
    "\n",
    "\n",
    "def load_df_and_annotate_anomalies(farm, event_id):\n",
    "    path = f\"../../../data/care_to_compare/Wind Farm {farm}/datasets/{event_id}.csv\"\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "\n",
    "    event_info = pd.read_csv(f\"../../../data/care_to_compare/Wind Farm {farm}/event_info.csv\", delimiter=';')\n",
    "\n",
    "    # Find the row where event_id = event_id\n",
    "    metadata = event_info[event_info['event_id'] == event_id]\n",
    "\n",
    "    event_label = metadata[\"event_label\"].values[0]\n",
    "    event_start_id = metadata[\"event_start_id\"].values[0]\n",
    "    event_end_id = metadata[\"event_end_id\"].values[0]\n",
    "\n",
    "    label_value = 1 if event_label == \"anomaly\" else 0\n",
    "\n",
    "    # All rows where the column \"id\" is between event_start_id and event_end_id\n",
    "    df['label'] = 0\n",
    "    df.loc[(df['id'] >= event_start_id) & (df['id'] <= event_end_id), 'label'] = label_value\n",
    "\n",
    "    # Include all columns except for the ones in exclude_columns\n",
    "    df = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_dataset(data: pd.DataFrame):\n",
    "    # Only include rows where the column \"train_test\" is \"train\"\n",
    "\n",
    "    df_prediction = data[data['train_test'] == 'prediction']\n",
    "    df_train = data[data['train_test'] == 'train']\n",
    "\n",
    "    df_anomalies = df_prediction[df_prediction['label'] == 1]\n",
    "    df_normal = df_train[df_train['label'] == 0]\n",
    "\n",
    "    # Take as many normal samples as there are anomalies\n",
    "    n = len(df_anomalies)\n",
    "\n",
    "    df_normal = df_normal.sample(n=n)\n",
    "\n",
    "    # Combine the two dataframes\n",
    "    df = pd.concat([df_normal, df_anomalies])\n",
    "\n",
    "    return df"
   ],
   "id": "890df7a6f9bbbd18",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:10:39.120251Z",
     "start_time": "2025-02-12T14:10:39.115550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_min_max(farm, dataset_ids):\n",
    "    # For each column get the min and max value\n",
    "    min_max_values = {}\n",
    "\n",
    "    for dataset_id in dataset_ids:\n",
    "        df = load_df_and_annotate_anomalies(farm, dataset_id)\n",
    "\n",
    "        for col in df.columns:\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "\n",
    "            if col not in min_max_values:\n",
    "                min_max_values[col] = (min_val, max_val)\n",
    "            else:\n",
    "                current_min, current_max = min_max_values[col]\n",
    "                min_max_values[col] = (min(min_val, current_min), max(max_val, current_max))\n",
    "\n",
    "    return min_max_values"
   ],
   "id": "a044eef9e1b7a0f8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:10:39.299771Z",
     "start_time": "2025-02-12T14:10:39.295149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_to_10bit_integers(df, minmax):\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        min_val = minmax[col][0]\n",
    "        max_val = minmax[col][1]\n",
    "\n",
    "        # Edge case where all values are 0\n",
    "        if min_val == max_val:\n",
    "            normalized_df[col] = 0\n",
    "        else:\n",
    "            normalized_df[col] = ((df[col] - min_val) / (max_val - min_val) * 1023)\n",
    "\n",
    "    # Convert the normalized values to integers\n",
    "    int_df = normalized_df.astype(int)\n",
    "\n",
    "    # Flatten each row into an array of 10-bit integers\n",
    "    int_arrays = int_df.apply(lambda row: row.values.flatten(), axis=1).tolist()\n",
    "\n",
    "    # Represent each cell as a 10-bit integer string\n",
    "    bin_arrays = [[f\"{cell:010b}\" for cell in row] for row in int_arrays]\n",
    "\n",
    "    # Split each 10-bit integer string into individual integers for each row\n",
    "    # preserve the columns of bin_arrays\n",
    "    bin_int_arrays = [[int(cell) for cell in list(''.join(row))] for row in bin_arrays]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    int_arrays = np.array(bin_int_arrays)\n",
    "\n",
    "    return int_arrays"
   ],
   "id": "383106dfae1e5bf4",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:10:39.513363Z",
     "start_time": "2025-02-12T14:10:39.508854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binarize_dataset_for_training(farm, event_id, output_path, min_max_values):\n",
    "    # Load original dataset from file\n",
    "    df = load_df_and_annotate_anomalies(farm, event_id)\n",
    "    df = split_dataset(df)\n",
    "\n",
    "    # Split into data and labels\n",
    "    X_values = df.drop(columns=['label', 'train_test', 'status_type_id'])\n",
    "    y_values = df['label']\n",
    "\n",
    "    X_values = X_values.apply(pd.to_numeric, errors='coerce')\n",
    "    X_values = X_values.dropna(axis=1)\n",
    "\n",
    "    X_values_bin = convert_to_10bit_integers(X_values, min_max_values).astype(np.uint32)\n",
    "    y_values_bin = y_values.values.astype(np.uint32)\n",
    "\n",
    "    # Output to file using np\n",
    "    np.savetxt(f\"{output_path}/X_{farm}_{event_id}_10b.txt\", X_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/y_{farm}_{event_id}_10b.txt\", y_values_bin, fmt='%d')\n",
    "\n",
    "    num_1s = np.count_nonzero(y_values_bin == 1)\n",
    "    num_0s = np.count_nonzero(y_values_bin == 0)\n",
    "\n",
    "    print(f\"Saved {event_id} to {output_path}\")\n",
    "    print(f\"Number of 1s: {num_1s}, Number of 0s: {num_0s}\")\n",
    "\n",
    "\n",
    "def binarize_dataset_for_testing(farm, event_id, output_path, min_max_values):\n",
    "    # Load original dataset from file\n",
    "    df = load_df_and_annotate_anomalies(farm, event_id)\n",
    "\n",
    "    # Split into data and labels\n",
    "    X_values = df.drop(columns=['label', 'train_test'])\n",
    "    y_values = df['label']\n",
    "    z_values = df['status_type_id']\n",
    "\n",
    "    X_values = X_values.apply(pd.to_numeric, errors='coerce')\n",
    "    X_values = X_values.dropna(axis=1)\n",
    "\n",
    "    X_values_bin = convert_to_10bit_integers(X_values, min_max_values).astype(np.uint32)\n",
    "    y_values_bin = y_values.values.astype(np.uint32)\n",
    "    z_valued_bin = z_values.values.astype(np.uint32)\n",
    "\n",
    "    # Output to file using np\n",
    "    np.savetxt(f\"{output_path}/X_{farm}_{event_id}_10b.txt\", X_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/y_{farm}_{event_id}_10b.txt\", y_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/z_{farm}_{event_id}_10b.txt\", z_valued_bin, fmt='%d')\n",
    "\n",
    "    num_1s = np.count_nonzero(y_values_bin == 1)\n",
    "    num_0s = np.count_nonzero(y_values_bin == 0)\n",
    "\n",
    "    print(f\"Saved {event_id} to {output_path}\")\n",
    "    print(f\"Number of 1s: {num_1s}, Number of 0s: {num_0s}\")"
   ],
   "id": "67a9eb610d672ee3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:10:39.784184Z",
     "start_time": "2025-02-12T14:10:39.781190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datasets = [49, 31, 67, 9, 91, 5, 90, 70, 35, 16, 76]\n",
    "test_datasets = [\n",
    "    55, 81, 47, 12, 4, 18, 28, 39, 66, 15, 78, 79, 30, 33, 11, 44,  # Has anomalies\n",
    "]\n",
    "\n",
    "#     8, 85, 6, 62, 36, 56, 94, 54, 43, 50, 64, 46, 65, 61, 93, 75, 41, 58, 48, 88, 57, 32, 89, 59, 63, 80, 37, 29, 1, 20, 60  # Without anomalies"
   ],
   "id": "7a7f1b244669456d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:11:53.109156Z",
     "start_time": "2025-02-12T14:10:40.305347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_max_values_dict = calculate_min_max(\"C\", train_datasets + test_datasets)\n",
    "\n",
    "# Save to file\n",
    "with open(\"min_max_values.txt\", \"w\") as f:\n",
    "    for key, value in min_max_values_dict.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "id": "b140f91bb2a74030",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:21:14.792738Z",
     "start_time": "2025-02-12T14:11:53.136600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in test_datasets:\n",
    "    binarize_dataset_for_testing(\"C\", dataset, \"./test_data\", min_max_values_dict)"
   ],
   "id": "e879c62b0a552f43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 55 to ./test_data\n",
      "Number of 1s: 2473, Number of 0s: 53280\n",
      "Saved 81 to ./test_data\n",
      "Number of 1s: 364, Number of 0s: 53568\n",
      "Saved 47 to ./test_data\n",
      "Number of 1s: 713, Number of 0s: 53280\n",
      "Saved 12 to ./test_data\n",
      "Number of 1s: 3259, Number of 0s: 52848\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m test_datasets:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mbinarize_dataset_for_testing\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./test_data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_max_values_dict\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[21], line 39\u001B[0m, in \u001B[0;36mbinarize_dataset_for_testing\u001B[0;34m(farm, event_id, output_path, min_max_values)\u001B[0m\n\u001B[1;32m     36\u001B[0m X_values \u001B[38;5;241m=\u001B[39m X_values\u001B[38;5;241m.\u001B[39mapply(pd\u001B[38;5;241m.\u001B[39mto_numeric, errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     37\u001B[0m X_values \u001B[38;5;241m=\u001B[39m X_values\u001B[38;5;241m.\u001B[39mdropna(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 39\u001B[0m X_values_bin \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_to_10bit_integers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_max_values\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint32)\n\u001B[1;32m     40\u001B[0m y_values_bin \u001B[38;5;241m=\u001B[39m y_values\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint32)\n\u001B[1;32m     41\u001B[0m z_valued_bin \u001B[38;5;241m=\u001B[39m z_values\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint32)\n",
      "Cell \u001B[0;32mIn[20], line 25\u001B[0m, in \u001B[0;36mconvert_to_10bit_integers\u001B[0;34m(df, minmax)\u001B[0m\n\u001B[1;32m     21\u001B[0m bin_arrays \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcell\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m010b\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m cell \u001B[38;5;129;01min\u001B[39;00m row] \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m int_arrays]\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Split each 10-bit integer string into individual integers for each row\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# preserve the columns of bin_arrays\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m bin_int_arrays \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;28mint\u001B[39m(cell) \u001B[38;5;28;01mfor\u001B[39;00m cell \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(row))] \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m bin_arrays]\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Convert to numpy array\u001B[39;00m\n\u001B[1;32m     28\u001B[0m int_arrays \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(bin_int_arrays)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T14:21:14.810367Z",
     "start_time": "2025-02-10T23:27:41.984633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in train_datasets:\n",
    "    binarize_dataset_for_training(\"C\", dataset, \"./train_data\", min_max_values_dict)"
   ],
   "id": "a312821be058472e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 49 to ./data\n",
      "Number of 1s: 598, Number of 0s: 598\n",
      "Saved 31 to ./data\n",
      "Number of 1s: 1008, Number of 0s: 1008\n",
      "Saved 67 to ./data\n",
      "Number of 1s: 576, Number of 0s: 576\n",
      "Saved 9 to ./data\n",
      "Number of 1s: 432, Number of 0s: 432\n",
      "Saved 91 to ./data\n",
      "Number of 1s: 1152, Number of 0s: 1152\n",
      "Saved 5 to ./data\n",
      "Number of 1s: 144, Number of 0s: 144\n",
      "Saved 90 to ./data\n",
      "Number of 1s: 576, Number of 0s: 576\n",
      "Saved 70 to ./data\n",
      "Number of 1s: 576, Number of 0s: 576\n",
      "Saved 35 to ./data\n",
      "Number of 1s: 288, Number of 0s: 288\n",
      "Saved 16 to ./data\n",
      "Number of 1s: 144, Number of 0s: 144\n",
      "Saved 76 to ./data\n",
      "Number of 1s: 246, Number of 0s: 246\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
