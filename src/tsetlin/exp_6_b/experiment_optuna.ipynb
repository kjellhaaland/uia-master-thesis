{
 "cells": [
  {
   "cell_type": "code",
   "id": "e28183c3-d395-4a3a-8eb4-dba55cb1d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:30.269459Z",
     "start_time": "2025-04-11T15:28:30.267472Z"
    }
   },
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install numpy==1.26.4"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2b757c20539f2247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:30.399627Z",
     "start_time": "2025-04-11T15:28:30.280213Z"
    }
   },
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from tmu.models.classification.vanilla_classifier import TMClassifier"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kjellhaaland/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-11 17:28:30,378 - tmu.util.cuda_profiler - WARNING - Could not import pycuda: No module named 'pycuda'\n",
      "2025-04-11 17:28:30,380 - tmu.clause_bank.clause_bank_cuda - ERROR - No module named 'pycuda'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kjellhaaland/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/tmu/clause_bank/clause_bank_cuda.py\", line 41, in <module>\n",
      "    from pycuda._driver import Device, Context\n",
      "ModuleNotFoundError: No module named 'pycuda'\n",
      "2025-04-11 17:28:30,382 - tmu.clause_bank.clause_bank_cuda - WARNING - Could not import pycuda. This indicates that it is not installed! A possible fix is to run 'pip install pycuda'. Fallback to CPU ClauseBanks.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:30.498214Z",
     "start_time": "2025-04-11T15:28:30.496446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datasets = np.array([34, 7, 53])\n",
    "test_datasets = np.array([27])"
   ],
   "id": "4f3db31b2e1a102a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:30.504538Z",
     "start_time": "2025-04-11T15:28:30.502177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create folder models if it does not exist\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ],
   "id": "d427f1ccd2f319f8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "28162fc330bc11f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:30.521343Z",
     "start_time": "2025-04-11T15:28:30.517486Z"
    }
   },
   "source": [
    "## Helper functions for saving the model and accuracy\n",
    "\n",
    "# Helper function to save the model\n",
    "def save_model(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "# Helper function to save the accuracy\n",
    "def save_accuracy(epoch, accuracy, tp, tn, fp, fn):\n",
    "    with open(\"accuracy.txt\", \"a\") as f:\n",
    "        f.write(f\"{epoch},{accuracy},{tp},{tn},{fp},{fn}\\n\")\n",
    "\n",
    "\n",
    "# Helper function to load dataset\n",
    "def load_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_dataset_labels(farm, event_id):\n",
    "    y = np.loadtxt(f\"./data_train/y_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    y = np.array(y).astype(np.uint32)\n",
    "    return y\n",
    "\n",
    "\n",
    "def load_test_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_test/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_dataset_labels(farm, event_id):\n",
    "    y = np.loadtxt(f\"./data_test/y_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    y = np.array(y).astype(np.uint32)\n",
    "    return y\n",
    "\n",
    "\n",
    "def get_train_dataset():\n",
    "    # Load all train datasets and concat them\n",
    "    dataset = np.concatenate([load_dataset(\"B\", dataset) for dataset in train_datasets])\n",
    "    labels = np.concatenate([load_dataset_labels(\"B\", dataset) for dataset in train_datasets])\n",
    "    return dataset, labels\n",
    "\n",
    "\n",
    "def get_test_dataset():\n",
    "    # Load all train datasets and concat them\n",
    "    dataset = np.concatenate([load_test_dataset(\"B\", dataset) for dataset in test_datasets])\n",
    "    labels = np.concatenate([load_test_dataset_labels(\"B\", dataset) for dataset in test_datasets])\n",
    "    return dataset, labels"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:31.000552Z",
     "start_time": "2025-04-11T15:28:30.556463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(X_train, y_train) = get_train_dataset()\n",
    "(X_test, y_test) = get_test_dataset()\n",
    "\n",
    "# Ensure that the the dataset can be divided by 250\n",
    "X_train = X_train[: len(X_train) - len(X_train) % 250]\n",
    "y_train = y_train[: len(y_train) - len(y_train) % 250]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ],
   "id": "a31d2f9342f1de77",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "./data_train/X_B_53.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m (X_train, y_train) \u001B[38;5;241m=\u001B[39m \u001B[43mget_train_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m (X_test, y_test) \u001B[38;5;241m=\u001B[39m get_test_dataset()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Ensure that the the dataset can be divided by 250\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[5], line 42\u001B[0m, in \u001B[0;36mget_train_dataset\u001B[0;34m()\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_train_dataset\u001B[39m():\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;66;03m# Load all train datasets and concat them\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([\u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m train_datasets])\n\u001B[1;32m     43\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([load_dataset_labels(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m, dataset) \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m train_datasets])\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dataset, labels\n",
      "Cell \u001B[0;32mIn[5], line 17\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(farm, event_id)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_dataset\u001B[39m(farm, event_id):\n\u001B[0;32m---> 17\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadtxt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./data_train/X_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mfarm\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mevent_id\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     X \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(X)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint32)\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:1373\u001B[0m, in \u001B[0;36mloadtxt\u001B[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001B[0m\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(delimiter, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[1;32m   1371\u001B[0m     delimiter \u001B[38;5;241m=\u001B[39m delimiter\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1373\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelimiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1374\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskiplines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1375\u001B[0m \u001B[43m            \u001B[49m\u001B[43munpack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munpack\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mndmin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1376\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:992\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001B[0m\n\u001B[1;32m    990\u001B[0m     fname \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(fname)\n\u001B[1;32m    991\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fname, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 992\u001B[0m     fh \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_datasource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    993\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m encoding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    994\u001B[0m         encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(fh, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:193\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(path, mode, destpath, encoding, newline)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;124;03mOpen `path` with `mode` and return the file object.\u001B[39;00m\n\u001B[1;32m    158\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    189\u001B[0m \n\u001B[1;32m    190\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    192\u001B[0m ds \u001B[38;5;241m=\u001B[39m DataSource(destpath)\n\u001B[0;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnewline\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:533\u001B[0m, in \u001B[0;36mDataSource.open\u001B[0;34m(self, path, mode, encoding, newline)\u001B[0m\n\u001B[1;32m    530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _file_openers[ext](found, mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[1;32m    531\u001B[0m                               encoding\u001B[38;5;241m=\u001B[39mencoding, newline\u001B[38;5;241m=\u001B[39mnewline)\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 533\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: ./data_train/X_B_53.txt not found."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:31.007891Z",
     "start_time": "2025-04-07T21:27:56.410498Z"
    }
   },
   "source": [
    "def run_evaluation(tm: TMClassifier) -> float:\n",
    "    pred = tm.predict(X_test)\n",
    "\n",
    "    accuracy = np.sum(pred == y_test) / len(y_test)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    number_of_features = X_train.shape[1]\n",
    "\n",
    "    number_of_clauses = trial.suggest_int(\"number_of_clauses\", 20, 15000)\n",
    "    T = trial.suggest_int(\"T\", 10, 10000)\n",
    "    s = trial.suggest_int(\"s\", 1, 100)\n",
    "    max_included_literals = trial.suggest_int(\"max_included_literals\", 1, 3 * number_of_features)\n",
    "\n",
    "    tm = TMClassifier(\n",
    "        number_of_clauses=number_of_clauses,\n",
    "        T=T,\n",
    "        s=s,\n",
    "        max_included_literals=max_included_literals,\n",
    "        weighted_clauses=True,\n",
    "        platform=\"CPU\",  # TODO: Change to CUDA\n",
    "        batch_size=250,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for trial {trial.number}\")\n",
    "\n",
    "    for e in range(5):\n",
    "        tm.fit(X_train, y_train)\n",
    "\n",
    "    # Write the current best result to file \"temp_best.txt\"\n",
    "    with open(\"temp_params.txt\", \"w\") as f:\n",
    "        f.write(f\"Trial: {trial.number}\\n\")\n",
    "\n",
    "    return run_evaluation(tm)\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "d4dc7e4da5c88e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:31.009186Z",
     "start_time": "2025-04-07T21:27:56.424516Z"
    }
   },
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=3)\n",
    "\n",
    "# Save the best params to file\n",
    "best_params = study.best_params\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "with open(\"best_params.txt\", \"w\") as f:\n",
    "    for key, value in best_params.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for trial 0\n",
      "Best params: {'number_of_clauses': 1762, 'T': 4365, 's': 63, 'max_included_literals': 666}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:28:31.009932Z",
     "start_time": "2025-04-07T21:28:43.279571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = study.best_params\n",
    "print(best_params)"
   ],
   "id": "704d8ae47917c45f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_clauses': 1762, 'T': 4365, 's': 63, 'max_included_literals': 666}\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
