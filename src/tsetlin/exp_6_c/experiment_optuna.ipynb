{
 "cells": [
  {
   "cell_type": "code",
   "id": "e28183c3-d395-4a3a-8eb4-dba55cb1d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:23:48.763165Z",
     "start_time": "2025-05-08T14:23:48.761727Z"
    }
   },
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install numpy==1.26.4"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2b757c20539f2247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:23:48.829297Z",
     "start_time": "2025-05-08T14:23:48.766334Z"
    }
   },
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from tmu.models.classification.vanilla_classifier import TMClassifier"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kjellhaaland/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 16:23:48,821 - tmu.util.cuda_profiler - WARNING - Could not import pycuda: No module named 'pycuda'\n",
      "2025-05-08 16:23:48,823 - tmu.clause_bank.clause_bank_cuda - ERROR - No module named 'pycuda'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kjellhaaland/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/tmu/clause_bank/clause_bank_cuda.py\", line 41, in <module>\n",
      "    from pycuda._driver import Device, Context\n",
      "ModuleNotFoundError: No module named 'pycuda'\n",
      "2025-05-08 16:23:48,824 - tmu.clause_bank.clause_bank_cuda - WARNING - Could not import pycuda. This indicates that it is not installed! A possible fix is to run 'pip install pycuda'. Fallback to CPU ClauseBanks.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:23:48.938165Z",
     "start_time": "2025-05-08T14:23:48.935366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datasets = np.array([55, 81, 47])\n",
    "test_datasets = np.array([33])"
   ],
   "id": "4f3db31b2e1a102a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:23:48.962831Z",
     "start_time": "2025-05-08T14:23:48.960857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create folder models if it does not exist\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ],
   "id": "d427f1ccd2f319f8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "28162fc330bc11f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:23:48.972666Z",
     "start_time": "2025-05-08T14:23:48.969074Z"
    }
   },
   "source": [
    "# Helper function to save the model\n",
    "def save_model(model, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "# Helper function to save the accuracy\n",
    "def save_accuracy(epoch, accuracy, tp, tn, fp, fn):\n",
    "    with open(\"accuracy.txt\", \"a\") as f:\n",
    "        f.write(f\"{epoch},{accuracy},{tp},{tn},{fp},{fn}\\n\")\n",
    "\n",
    "\n",
    "# Helper function to load dataset\n",
    "def load_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_dataset_labels(farm, event_id):\n",
    "    y = np.loadtxt(f\"./data_train/y_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    y = np.array(y).astype(np.uint32)\n",
    "    return y\n",
    "\n",
    "\n",
    "def load_test_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_test/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_dataset_labels(farm, event_id):\n",
    "    y = np.loadtxt(f\"./data_test/y_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    y = np.array(y).astype(np.uint32)\n",
    "    return y\n",
    "\n",
    "\n",
    "def get_train_dataset():\n",
    "    # Load all train datasets and concat them\n",
    "    dataset = np.concatenate([load_dataset(\"C\", dataset) for dataset in train_datasets])\n",
    "    labels = np.concatenate([load_dataset_labels(\"C\", dataset) for dataset in train_datasets])\n",
    "    return dataset, labels\n",
    "\n",
    "\n",
    "def get_test_dataset():\n",
    "    # Load all train datasets and concat them\n",
    "    dataset = np.concatenate([load_test_dataset(\"C\", dataset) for dataset in test_datasets])\n",
    "    labels = np.concatenate([load_test_dataset_labels(\"C\", dataset) for dataset in test_datasets])\n",
    "    return dataset, labels"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:23:49.676141Z",
     "start_time": "2025-05-08T14:23:48.977944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(X_train, y_train) = get_train_dataset()\n",
    "(X_test, y_test) = get_test_dataset()\n",
    "\n",
    "# Ensure that the the dataset can be divided by 250\n",
    "X_train = X_train[: len(X_train) - len(X_train) % 250]\n",
    "y_train = y_train[: len(y_train) - len(y_train) % 250]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ],
   "id": "a31d2f9342f1de77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6500, 4760)\n",
      "y_train shape: (6500,)\n",
      "X_test shape: (3313, 4760)\n",
      "y_test shape: (3313,)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:23:49.684711Z",
     "start_time": "2025-05-08T14:23:49.681454Z"
    }
   },
   "source": [
    "def run_evaluation(tm: TMClassifier) -> float:\n",
    "    pred = tm.predict(X_test)\n",
    "\n",
    "    accuracy = np.sum(pred == y_test) / len(y_test)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    number_of_features = X_train.shape[1]\n",
    "\n",
    "    number_of_clauses = trial.suggest_int(\"number_of_clauses\", 20, 15000, 2)\n",
    "    T = trial.suggest_int(\"T\", 20, 10000, 2)\n",
    "    s = trial.suggest_float(\"s\", 1, 50)\n",
    "    max_included_literals = trial.suggest_int(\"max_included_literals\", 20, 3 * number_of_features, 2)\n",
    "\n",
    "    tm = TMClassifier(\n",
    "        number_of_clauses=number_of_clauses,\n",
    "        T=T,\n",
    "        s=s,\n",
    "        max_included_literals=max_included_literals,\n",
    "        weighted_clauses=True,\n",
    "        platform=\"CPU\",  # TODO: Change to CUDA\n",
    "        batch_size=250,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for trial {trial.number}\")\n",
    "\n",
    "    for e in range(5):\n",
    "        tm.fit(X_train, y_train)\n",
    "\n",
    "    # Write the current best result to file \"temp_best.txt\"\n",
    "    with open(\"temp_params.txt\", \"w\") as f:\n",
    "        f.write(f\"Trial: {trial.number}\\n\")\n",
    "\n",
    "    return run_evaluation(tm)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d4dc7e4da5c88e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T17:54:41.364109Z",
     "start_time": "2025-05-08T14:23:49.694909Z"
    }
   },
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Save the best params to file\n",
    "best_params = study.best_params\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "with open(\"best_params.txt\", \"w\") as f:\n",
    "    for key, value in best_params.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for trial 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/ltvwyfm53nb435_nt2n_7b9h0000gn/T/ipykernel_56149/3650525195.py:12: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  number_of_clauses = trial.suggest_int(\"number_of_clauses\", 20, 15000, 2)\n",
      "/var/folders/3f/ltvwyfm53nb435_nt2n_7b9h0000gn/T/ipykernel_56149/3650525195.py:13: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  T = trial.suggest_int(\"T\", 20, 10000, 2)\n",
      "/var/folders/3f/ltvwyfm53nb435_nt2n_7b9h0000gn/T/ipykernel_56149/3650525195.py:15: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_included_literals = trial.suggest_int(\"max_included_literals\", 20, 3 * number_of_features, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for trial 1\n",
      "Starting training for trial 2\n",
      "Starting training for trial 3\n",
      "Starting training for trial 4\n",
      "Starting training for trial 5\n",
      "Starting training for trial 6\n",
      "Starting training for trial 7\n",
      "Starting training for trial 8\n",
      "Starting training for trial 9\n",
      "Starting training for trial 10\n",
      "Starting training for trial 11\n",
      "Starting training for trial 12\n",
      "Starting training for trial 13\n",
      "Starting training for trial 14\n",
      "Starting training for trial 15\n",
      "Starting training for trial 16\n",
      "Starting training for trial 17\n",
      "Starting training for trial 18\n",
      "Starting training for trial 19\n",
      "Starting training for trial 20\n",
      "Starting training for trial 21\n",
      "Starting training for trial 22\n",
      "Starting training for trial 23\n",
      "Starting training for trial 24\n",
      "Starting training for trial 25\n",
      "Starting training for trial 26\n",
      "Starting training for trial 27\n",
      "Starting training for trial 28\n",
      "Starting training for trial 29\n",
      "Starting training for trial 30\n",
      "Starting training for trial 31\n",
      "Starting training for trial 32\n",
      "Starting training for trial 33\n",
      "Starting training for trial 34\n",
      "Starting training for trial 35\n",
      "Starting training for trial 36\n",
      "Starting training for trial 37\n",
      "Starting training for trial 38\n",
      "Starting training for trial 39\n",
      "Starting training for trial 40\n",
      "Starting training for trial 41\n",
      "Starting training for trial 42\n",
      "Starting training for trial 43\n",
      "Starting training for trial 44\n",
      "Starting training for trial 45\n",
      "Starting training for trial 46\n",
      "Starting training for trial 47\n",
      "Starting training for trial 48\n",
      "Starting training for trial 49\n",
      "Best params: {'number_of_clauses': 2140, 'T': 4622, 's': 23.706791496433414, 'max_included_literals': 8658}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T17:54:41.614679Z",
     "start_time": "2025-05-08T17:54:41.609203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = study.best_params\n",
    "print(best_params)"
   ],
   "id": "704d8ae47917c45f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_clauses': 2140, 'T': 4622, 's': 23.706791496433414, 'max_included_literals': 8658}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T17:54:46.050324Z",
     "start_time": "2025-05-08T17:54:41.846902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# Set default template to white\n",
    "pio.templates.default = \"plotly_white\"\n",
    "# Create plots and save them as PDF\n",
    "\n",
    "# 1. Optimization history\n",
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.write_image('optimization_history.pdf')\n",
    "\n",
    "# 2. Parameter importances\n",
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.write_image('param_importances.pdf')\n",
    "\n",
    "# 3. Parallel coordinate plot\n",
    "fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "fig.write_image('parallel_coordinate.pdf')\n",
    "\n",
    "# 4. Slice plot\n",
    "fig = optuna.visualization.plot_slice(study)\n",
    "fig.write_image('slice_plot.pdf')\n",
    "\n",
    "# 5. Contour plot (for 2 parameters)\n",
    "if len(study.best_params) >= 2:\n",
    "    params = list(study.best_params.keys())[:2]\n",
    "    fig = optuna.visualization.plot_contour(study, params=params)\n",
    "    fig.write_image('contour_plot.pdf')\n",
    "\n",
    "# 6. EDF plot\n",
    "fig = optuna.visualization.plot_edf(study)\n",
    "fig.write_image('edf_plot.pdf')\n",
    "\n"
   ],
   "id": "a01f3127014dc371",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T17:54:46.059302Z",
     "start_time": "2025-05-08T17:54:46.058013Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "337deddc279cb76f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
