{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment description\n",
    "\n",
    "The goal of this notebook is to preprocess all datasets in Wind Farm C to a binary format that can be used for training a TM Classifier."
   ],
   "id": "e85b94674bcffa5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:13:46.457161Z",
     "start_time": "2025-03-14T04:13:46.450951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "a7fa0f63187f7de2",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:13:46.481056Z",
     "start_time": "2025-03-14T04:13:46.473434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exclude_columns = [\"time_stamp\", \"asset_id\", \"id\"]\n",
    "\n",
    "\n",
    "def load_df_and_annotate_anomalies(farm, event_id):\n",
    "    path = f\"../../../data/care_to_compare/Wind Farm {farm}/datasets/{event_id}.csv\"\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "\n",
    "    event_info = pd.read_csv(f\"../../../data/care_to_compare/Wind Farm {farm}/event_info.csv\", delimiter=';')\n",
    "\n",
    "    # Find the row where event_id = event_id\n",
    "    metadata = event_info[event_info['event_id'] == event_id]\n",
    "\n",
    "    event_label = metadata[\"event_label\"].values[0]\n",
    "    event_start_id = metadata[\"event_start_id\"].values[0]\n",
    "    event_end_id = metadata[\"event_end_id\"].values[0]\n",
    "\n",
    "    label_value = 1 if event_label == \"anomaly\" else 0\n",
    "\n",
    "    # All rows where the column \"id\" is between event_start_id and event_end_id\n",
    "    df['label'] = 0\n",
    "    df.loc[(df['id'] >= event_start_id) & (df['id'] <= event_end_id), 'label'] = label_value\n",
    "\n",
    "    # Include all columns except for the ones in exclude_columns\n",
    "    df = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "\n",
    "    # Remove columns with suffixes in exclude_columns_with_suffix\n",
    "    df = df[[col for col in df.columns if not col.endswith('_max')]]\n",
    "    df = df[[col for col in df.columns if not col.endswith('_min')]]\n",
    "    df = df[[col for col in df.columns if not col.endswith('_std')]]\n",
    "\n",
    "    return df"
   ],
   "id": "890df7a6f9bbbd18",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:13:46.491992Z",
     "start_time": "2025-03-14T04:13:46.488625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_min_max(farm, dataset_ids):\n",
    "    # For each column get the min and max value\n",
    "    min_max_values = {}\n",
    "\n",
    "    for dataset_id in dataset_ids:\n",
    "        df = load_df_and_annotate_anomalies(farm, dataset_id)\n",
    "\n",
    "        for col in df.columns:\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "\n",
    "            if col not in min_max_values:\n",
    "                min_max_values[col] = (min_val, max_val)\n",
    "            else:\n",
    "                current_min, current_max = min_max_values[col]\n",
    "                min_max_values[col] = (min(min_val, current_min), max(max_val, current_max))\n",
    "\n",
    "    return min_max_values"
   ],
   "id": "a044eef9e1b7a0f8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:13:46.508543Z",
     "start_time": "2025-03-14T04:13:46.504798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_to_bit_integers(df, minmax, bits_per_column=8):\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        min_val = minmax[col][0]\n",
    "        max_val = minmax[col][1]\n",
    "\n",
    "        shifted = normalized_df[col] - min_val + 1\n",
    "        log_data = np.log1p(shifted)\n",
    "\n",
    "        global_log_min = np.log1p(1)  # log1p(1) because shift guarantees min = 1\n",
    "        global_log_max = np.log1p(max_val - min_val + 1)  # Max in transformed space\n",
    "\n",
    "        normalized_df[col] = (log_data - global_log_min) / (global_log_max - global_log_min) * (\n",
    "                (2 ** bits_per_column) - 1)\n",
    "\n",
    "    # Convert the normalized values to integers\n",
    "    int_df = normalized_df.astype(int)\n",
    "\n",
    "    # Flatten each row into an array of 10-bit integers\n",
    "    int_arrays = int_df.apply(lambda row: row.values.flatten(), axis=1).tolist()\n",
    "\n",
    "    # Represent each cell as a 10-bit integer string\n",
    "    bin_arrays = [[f\"{cell:0{bits_per_column}b}\" for cell in row] for row in int_arrays]\n",
    "\n",
    "    # Split each 10-bit integer string into individual integers for each row\n",
    "    # preserve the columns of bin_arrays\n",
    "    bin_int_arrays = [[int(cell) for cell in list(''.join(row))] for row in bin_arrays]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    int_arrays = np.array(bin_int_arrays)\n",
    "\n",
    "    return int_arrays"
   ],
   "id": "383106dfae1e5bf4",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:13:46.520868Z",
     "start_time": "2025-03-14T04:13:46.514934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binarize_dataset_for_training(farm, event_id, output_path, min_max_values, bits_per_column=8):\n",
    "    # Load original dataset from file\n",
    "    df = load_df_and_annotate_anomalies(farm, event_id)\n",
    "    df = df[df['train_test'] == 'train']\n",
    "\n",
    "    # Remove all rows where status_type_id is not 0 or 2\n",
    "    df = df[df['status_type_id'].isin([0, 2])]\n",
    "\n",
    "    # Split into data and labels\n",
    "    X_values = df.drop(columns=['label', 'train_test', 'status_type_id'])\n",
    "    y_values = df['label']\n",
    "\n",
    "    X_values = X_values.apply(pd.to_numeric, errors='coerce')\n",
    "    X_values = X_values.dropna(axis=1)\n",
    "\n",
    "    # Print number of columns\n",
    "    print(f\"Number of features: {len(X_values.columns)}\")\n",
    "\n",
    "    X_values_bin = convert_to_bit_integers(X_values, min_max_values, bits_per_column).astype(np.uint32)\n",
    "    y_values_bin = y_values.values.astype(np.uint32)\n",
    "\n",
    "    print(f\"Number of columns: {X_values_bin.shape[1]}\")\n",
    "\n",
    "    # Output to file using np\n",
    "    np.savetxt(f\"{output_path}/X_{farm}_{event_id}.txt\", X_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/y_{farm}_{event_id}.txt\", y_values_bin, fmt='%d')\n",
    "\n",
    "    num_1s = np.count_nonzero(y_values_bin == 1)\n",
    "    num_0s = np.count_nonzero(y_values_bin == 0)\n",
    "\n",
    "    print(f\"Saved {event_id} to {output_path}\")\n",
    "    print(f\"Number of 1s: {num_1s}, Number of 0s: {num_0s}\")\n",
    "\n",
    "\n",
    "def binarize_dataset_for_testing(farm, event_id, output_path, min_max_values, bits_per_column=8):\n",
    "    # Load original dataset from file\n",
    "    df = load_df_and_annotate_anomalies(farm, event_id)\n",
    "\n",
    "    #df = df[df['train_test'] == 'prediction']\n",
    "    #df = df[df['label'] == 1]\n",
    "\n",
    "    # Split into data and labels\n",
    "    X_values = df.drop(columns=['label', 'train_test', 'status_type_id'])\n",
    "    y_values = df['label']\n",
    "    z_values = df['status_type_id']\n",
    "\n",
    "    X_values = X_values.apply(pd.to_numeric, errors='coerce')\n",
    "    X_values = X_values.dropna(axis=1)\n",
    "\n",
    "    # Print number of columns\n",
    "    print(f\"Number of features: {len(X_values.columns)}\")\n",
    "\n",
    "    X_values_bin = convert_to_bit_integers(X_values, min_max_values, bits_per_column).astype(np.uint32)\n",
    "    y_values_bin = y_values.values.astype(np.uint32)\n",
    "    z_valued_bin = z_values.values.astype(np.uint32)\n",
    "\n",
    "    print(f\"Number of columns: {X_values_bin.shape[1]}\")\n",
    "\n",
    "    # Output to file using np\n",
    "    np.savetxt(f\"{output_path}/X_{farm}_{event_id}.txt\", X_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/y_{farm}_{event_id}.txt\", y_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/z_{farm}_{event_id}.txt\", z_valued_bin, fmt='%d')\n",
    "\n",
    "    num_1s = np.count_nonzero(y_values_bin == 1)\n",
    "    num_0s = np.count_nonzero(y_values_bin == 0)\n",
    "\n",
    "    print(f\"Saved {event_id} to {output_path}\")\n",
    "    print(f\"Number of 1s: {num_1s}, Number of 0s: {num_0s}\")"
   ],
   "id": "67a9eb610d672ee3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:13:46.529986Z",
     "start_time": "2025-03-14T04:13:46.527942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datasets = [83, 52, 21, 2, 23, 87, 74, 86, 82]\n",
    "test_datasets = [34, 7, 53, 27, 19, 77, 83, 52, 21, 2, 23, 87, 74, 86, 82]"
   ],
   "id": "7a7f1b244669456d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:14:04.670611Z",
     "start_time": "2025-03-14T04:13:46.543252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_max_values_dict = calculate_min_max(\"B\", train_datasets + test_datasets)\n",
    "\n",
    "# Save to file\n",
    "with open(\"min_max_values.txt\", \"w\") as f:\n",
    "    for key, value in min_max_values_dict.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "id": "b140f91bb2a74030",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:14:04.686819Z",
     "start_time": "2025-03-14T04:14:04.684239Z"
    }
   },
   "cell_type": "code",
   "source": "bits = 5",
   "id": "a824517b052b4a92",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:15:25.859988Z",
     "start_time": "2025-03-14T04:14:04.696226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in test_datasets:\n",
    "    binarize_dataset_for_testing(\"B\", dataset, \"./data_test\", min_max_values_dict, bits)"
   ],
   "id": "e879c62b0a552f43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 34 to ./data_test\n",
      "Number of 1s: 3169, Number of 0s: 53395\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 7 to ./data_test\n",
      "Number of 1s: 4465, Number of 0s: 53423\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 53 to ./data_test\n",
      "Number of 1s: 6048, Number of 0s: 52559\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 27 to ./data_test\n",
      "Number of 1s: 8785, Number of 0s: 53483\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 19 to ./data_test\n",
      "Number of 1s: 2881, Number of 0s: 53393\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 77 to ./data_test\n",
      "Number of 1s: 8641, Number of 0s: 53135\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 83 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 66154\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 52 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 55268\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 21 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 53514\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 2 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 54774\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 23 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 54542\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 87 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 55356\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 74 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 55602\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 86 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 55486\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 82 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 54992\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:15:45.372652Z",
     "start_time": "2025-03-14T04:15:25.876549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in train_datasets:\n",
    "    binarize_dataset_for_training(\"B\", dataset, \"./data_train\", min_max_values_dict, bits)"
   ],
   "id": "a312821be058472e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 83 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 45750\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 52 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 43994\n",
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 21 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 47997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x107239490>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kjellhaaland/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 63\n",
      "Number of columns: 315\n",
      "Saved 2 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 44885\n",
      "Number of features: 63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m train_datasets:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mbinarize_dataset_for_training\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./data_train\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_max_values_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[25], line 19\u001B[0m, in \u001B[0;36mbinarize_dataset_for_training\u001B[0;34m(farm, event_id, output_path, min_max_values, bits_per_column)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Print number of columns\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of features: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(X_values\u001B[38;5;241m.\u001B[39mcolumns)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 19\u001B[0m X_values_bin \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_to_bit_integers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_max_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits_per_column\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint32)\n\u001B[1;32m     20\u001B[0m y_values_bin \u001B[38;5;241m=\u001B[39m y_values\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint32)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of columns: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mX_values_bin\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[24], line 21\u001B[0m, in \u001B[0;36mconvert_to_bit_integers\u001B[0;34m(df, minmax, bits_per_column)\u001B[0m\n\u001B[1;32m     18\u001B[0m int_df \u001B[38;5;241m=\u001B[39m normalized_df\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Flatten each row into an array of 10-bit integers\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m int_arrays \u001B[38;5;241m=\u001B[39m \u001B[43mint_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Represent each cell as a 10-bit integer string\u001B[39;00m\n\u001B[1;32m     24\u001B[0m bin_arrays \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcell\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m0\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbits_per_column\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mb\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m cell \u001B[38;5;129;01min\u001B[39;00m row] \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m int_arrays]\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m  10360\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m  10362\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m  10363\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m  10364\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m  10372\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m  10373\u001B[0m )\n\u001B[0;32m> 10374\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/apply.py:916\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw(engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine, engine_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine_kwargs)\n\u001B[0;32m--> 916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1068\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1065\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_numba()\n\u001B[1;32m   1067\u001B[0m \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[0;32m-> 1068\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrap_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mres_index\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1107\u001B[0m, in \u001B[0;36mFrameApply.wrap_results\u001B[0;34m(self, results, res_index)\u001B[0m\n\u001B[1;32m   1105\u001B[0m \u001B[38;5;66;03m# see if we can infer the results\u001B[39;00m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(results) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01min\u001B[39;00m results \u001B[38;5;129;01mand\u001B[39;00m is_sequence(results[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m-> 1107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrap_results_for_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mres_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1109\u001B[0m \u001B[38;5;66;03m# dict of scalars\u001B[39;00m\n\u001B[1;32m   1110\u001B[0m \n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# the default dtype of an empty Series is `object`, but this\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m \u001B[38;5;66;03m# code can be hit by df.mean() where the result should have dtype\u001B[39;00m\n\u001B[1;32m   1113\u001B[0m \u001B[38;5;66;03m# float64 even if it's an empty Series.\u001B[39;00m\n\u001B[1;32m   1114\u001B[0m constructor_sliced \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_constructor_sliced\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1349\u001B[0m, in \u001B[0;36mFrameColumnApply.wrap_results_for_axis\u001B[0;34m(self, results, res_index)\u001B[0m\n\u001B[1;32m   1347\u001B[0m \u001B[38;5;66;03m# we have a non-series and don't want inference\u001B[39;00m\n\u001B[1;32m   1348\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m-> 1349\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_constructor_sliced\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1350\u001B[0m     result\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m res_index\n\u001B[1;32m   1352\u001B[0m \u001B[38;5;66;03m# we may want to infer results\u001B[39;00m\n\u001B[1;32m   1353\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/series.py:537\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    535\u001B[0m         data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39m_mgr\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, Mapping):\n\u001B[0;32m--> 537\u001B[0m     data, index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    539\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/series.py:651\u001B[0m, in \u001B[0;36mSeries._init_dict\u001B[0;34m(self, data, index, dtype)\u001B[0m\n\u001B[1;32m    648\u001B[0m     keys, values \u001B[38;5;241m=\u001B[39m default_index(\u001B[38;5;241m0\u001B[39m), []\n\u001B[1;32m    650\u001B[0m \u001B[38;5;66;03m# Input is now list-like, so rely on \"standard\" construction:\u001B[39;00m\n\u001B[0;32m--> 651\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[38;5;66;03m# Now we just make sure the order is respected, if any\u001B[39;00m\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/series.py:490\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    487\u001B[0m name \u001B[38;5;241m=\u001B[39m ibase\u001B[38;5;241m.\u001B[39mmaybe_extract_name(name, data, \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m))\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 490\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[43mensure_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    493\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_dtype(dtype)\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7649\u001B[0m, in \u001B[0;36mensure_index\u001B[0;34m(index_like, copy)\u001B[0m\n\u001B[1;32m   7647\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m Index(index_like, copy\u001B[38;5;241m=\u001B[39mcopy, tupleize_cols\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   7648\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 7649\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mIndex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:565\u001B[0m, in \u001B[0;36mIndex.__new__\u001B[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001B[0m\n\u001B[1;32m    562\u001B[0m         data \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39masarray_tuplesafe(data, dtype\u001B[38;5;241m=\u001B[39m_dtype_obj)\n\u001B[1;32m    564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 565\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43msanitize_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    567\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex must be specified when data is not list-like\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(err):\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/construction.py:654\u001B[0m, in \u001B[0;36msanitize_array\u001B[0;34m(data, index, dtype, copy, allow_2d)\u001B[0m\n\u001B[1;32m    651\u001B[0m     subarr \u001B[38;5;241m=\u001B[39m _try_cast(data, dtype, copy)\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 654\u001B[0m     subarr \u001B[38;5;241m=\u001B[39m \u001B[43mmaybe_convert_platform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    655\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m subarr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[1;32m    656\u001B[0m         subarr \u001B[38;5;241m=\u001B[39m cast(np\u001B[38;5;241m.\u001B[39mndarray, subarr)\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:138\u001B[0m, in \u001B[0;36mmaybe_convert_platform\u001B[0;34m(values)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m _dtype_obj:\n\u001B[1;32m    137\u001B[0m     arr \u001B[38;5;241m=\u001B[39m cast(np\u001B[38;5;241m.\u001B[39mndarray, arr)\n\u001B[0;32m--> 138\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_convert_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:15:45.378184Z",
     "start_time": "2025-03-14T03:00:38.869742Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ec793e65dd6df0c2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
