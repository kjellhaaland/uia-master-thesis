{
 "cells": [
  {
   "cell_type": "code",
   "id": "e28183c3-d395-4a3a-8eb4-dba55cb1d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:09.909122Z",
     "start_time": "2025-03-23T23:30:09.895458Z"
    }
   },
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install numpy==1.26.4"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "2b757c20539f2247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:09.935733Z",
     "start_time": "2025-03-23T23:30:09.931328Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from tmu.models.autoencoder.autoencoder import TMAutoEncoder"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:09.951673Z",
     "start_time": "2025-03-23T23:30:09.949894Z"
    }
   },
   "cell_type": "code",
   "source": "bits = 10",
   "id": "828299cb718d1bb4",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:09.964157Z",
     "start_time": "2025-03-23T23:30:09.961576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create folder models if it does not exist\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ],
   "id": "d427f1ccd2f319f8",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "28162fc330bc11f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:09.976673Z",
     "start_time": "2025-03-23T23:30:09.972272Z"
    }
   },
   "source": [
    "def load_train_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_test/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "\n",
    "    # Take a sample of 5000 rows\n",
    "    X = X[:5000]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_labels(farm, event_id):\n",
    "    y = np.loadtxt(f\"./data_test/y_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    y = np.array(y).astype(np.uint32)\n",
    "\n",
    "    # Take a sample of 5000 rows\n",
    "    y = y[:5000]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def load_thresh_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "\n",
    "    # Take the first 5000 rows\n",
    "    X = X[:5000]\n",
    "\n",
    "    return X\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "da4ff95f-ff25-4203-89c8-7e6046e4356b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:09.984582Z",
     "start_time": "2025-03-23T23:30:09.981471Z"
    }
   },
   "source": [
    "def save_model(tm: TMAutoEncoder, filename: str):\n",
    "    a, d = tm.X_train, tm.encoded_X_train\n",
    "\n",
    "    tm.X_train = None\n",
    "    tm.encoded_X_train = None\n",
    "\n",
    "    with open(f\"./models/{filename}\", \"wb\") as f:\n",
    "        pickle.dump(tm, f)\n",
    "\n",
    "    tm.X_train = a\n",
    "    tm.encoded_X_train = d"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:10.783199Z",
     "start_time": "2025-03-23T23:30:09.992057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: Load X_train from a dataset\n",
    "\n",
    "train_datasets = [25, 69, 13]  #, 24, 3, 17, 38, 71, 14, 92, 51]\n",
    "test_dataset = [51]\n",
    "\n",
    "# Load all datasets into one array\n",
    "X_train = np.concatenate([load_train_dataset(\"A\", i) for i in train_datasets])\n",
    "\n",
    "X_test = np.concatenate([load_test_dataset(\"A\", i) for i in test_dataset])\n",
    "y_test = np.concatenate([load_test_labels(\"A\", i) for i in test_dataset])\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ],
   "id": "a31d2f9342f1de77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (119797, 432)\n",
      "X_test shape: (2393, 432)\n",
      "y_test shape: (2393,)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:10.798904Z",
     "start_time": "2025-03-23T23:30:10.789580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_to_float(bin_array):\n",
    "    \"\"\"Convert a 10-bit binary array to a float between 0 and 1.\"\"\"\n",
    "    return np.dot(bin_array, 2 ** np.arange(len(bin_array))[::-1]) / (2 ** len(bin_array) - 1)\n",
    "\n",
    "\n",
    "def mse_loss(X, pred, bits_per_value=bits):\n",
    "    \"\"\"\n",
    "    Compute MSE loss for flattened binary inputs.\n",
    "    - X and pred are 1D arrays of length `num_values * bits_per_value`.\n",
    "    - We reshape them into (num_values, bits_per_value) before converting.\n",
    "    \"\"\"\n",
    "\n",
    "    num_values = int(len(X) // bits_per_value)\n",
    "\n",
    "    # Reshape into (num_values, bits_per_value)\n",
    "    X_reshaped = X.reshape(num_values, bits_per_value)\n",
    "    pred_reshaped = pred.reshape(num_values, bits_per_value)\n",
    "\n",
    "    # Convert binary sequences back to float values\n",
    "    X_floats = np.array([binary_to_float(row) for row in X_reshaped])\n",
    "    pred_floats = np.array([binary_to_float(row) for row in pred_reshaped])\n",
    "\n",
    "    # Compute MSE\n",
    "    mse = np.mean((X_floats - pred_floats) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def mae_loss(X, pred, bits_per_value=bits):\n",
    "    \"\"\"\n",
    "    Compute MAE loss for flattened binary inputs.\n",
    "    - X and pred are 1D arrays of length `num_values * bits_per_value`.\n",
    "    - We reshape them into (num_values, bits_per_value) before converting.\n",
    "    \"\"\"\n",
    "\n",
    "    num_values = int(len(X) // bits_per_value)\n",
    "\n",
    "    # Reshape into (num_values, bits_per_value)\n",
    "    X_reshaped = X.reshape(num_values, bits_per_value)\n",
    "    pred_reshaped = pred.reshape(num_values, bits_per_value)\n",
    "\n",
    "    # Convert binary sequences back to float values\n",
    "    X_floats = np.array([binary_to_float(row) for row in X_reshaped])\n",
    "    pred_floats = np.array([binary_to_float(row) for row in pred_reshaped])\n",
    "\n",
    "    # Compute MAE\n",
    "    mae = np.mean(np.abs(X_floats - pred_floats))\n",
    "    return mae\n",
    "\n",
    "\n",
    "def hamming_loss(pred, X_test):\n",
    "    \"\"\"\n",
    "    Computes the Hamming loss between predicted and ground truth binary arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - pred (numpy array): Binary predictions of shape (n_samples, n_bits).\n",
    "    - X_test (numpy array): Ground truth binary values of shape (n_samples, n_bits).\n",
    "\n",
    "    Returns:\n",
    "    - float: Hamming loss (fraction of incorrect bits).\n",
    "    \"\"\"\n",
    "    assert pred.shape == X_test.shape, \"Shapes of pred and X_test must match\"\n",
    "\n",
    "    # Compute the number of differing bits\n",
    "    incorrect_bits = np.sum(pred != X_test)\n",
    "\n",
    "    # Total number of bits\n",
    "    total_bits = np.prod(X_test.shape)\n",
    "\n",
    "    # Hamming loss is the fraction of incorrect bits\n",
    "    return incorrect_bits / total_bits"
   ],
   "id": "99456064a07d2ee8",
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T23:30:10.829344Z",
     "start_time": "2025-03-23T23:30:10.814748Z"
    }
   },
   "source": [
    "def run_evaluation(tm: TMAutoEncoder) -> float:\n",
    "    pred = tm.predict(X_test)\n",
    "\n",
    "    loss = [hamming_loss(X_test[i], pred[i]) for i in range(len(X_test))]\n",
    "\n",
    "    print(f\"Mean loss: {np.mean(loss)}, Median loss: {np.median(loss)}, Max loss: {np.max(loss)}\")\n",
    "\n",
    "    # Mean loss for 0s\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    number_of_features = X_train.shape[1]\n",
    "    output_active = np.arange(number_of_features, dtype=np.uint32)\n",
    "\n",
    "    number_of_clauses = trial.suggest_int(\"number_of_clauses\", 20, 2000)\n",
    "    T = trial.suggest_int(\"T\", 20, 10000)\n",
    "    s = trial.suggest_int(\"s\", 1, 100)\n",
    "    max_included_literals = trial.suggest_int(\"max_included_literals\", 1, 3 * number_of_features)\n",
    "    accumulation = trial.suggest_int(\"accumulation\", 1, 10)\n",
    "    feature_negation = trial.suggest_categorical(\"feature_negation\", [True, False])\n",
    "    output_balancing = trial.suggest_float(\"output_balancing\", 0, 10)\n",
    "    number_of_examples = trial.suggest_int(\"number_of_examples\", 100, 100)\n",
    "\n",
    "    tm = TMAutoEncoder(\n",
    "        number_of_clauses=number_of_clauses,\n",
    "        T=T,\n",
    "        s=s,\n",
    "        output_active=output_active,\n",
    "        max_included_literals=max_included_literals,\n",
    "        accumulation=accumulation,\n",
    "        feature_negation=feature_negation,\n",
    "        platform=\"CPU\",  # TODO: Change to CUDA\n",
    "        output_balancing=output_balancing,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for trial {trial.number}\")\n",
    "\n",
    "    for e in range(5):\n",
    "        tm.fit(X_train, number_of_examples=number_of_examples)\n",
    "\n",
    "    return run_evaluation(tm)\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "d4dc7e4da5c88e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:52:48.786117Z",
     "start_time": "2025-03-23T23:30:11.009053Z"
    }
   },
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "# Save the best params to file\n",
    "best_params = study.best_params\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "with open(\"best_params.txt\", \"w\") as f:\n",
    "    for key, value in best_params.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for trial 0\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 1\n",
      "Mean loss: 0.42662240175821453, Median loss: 0.4305555555555556, Max loss: 0.5416666666666666\n",
      "Starting training for trial 2\n",
      "Mean loss: 0.6043001578678553, Median loss: 0.6134259259259259, Max loss: 0.7060185185185185\n",
      "Starting training for trial 3\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 4\n",
      "Mean loss: 0.4278857315317825, Median loss: 0.4305555555555556, Max loss: 0.6527777777777778\n",
      "Starting training for trial 5\n",
      "Mean loss: 0.5750404342913745, Median loss: 0.5717592592592593, Max loss: 0.6851851851851852\n",
      "Starting training for trial 6\n",
      "Mean loss: 0.512250236027921, Median loss: 0.5486111111111112, Max loss: 0.6712962962962963\n",
      "Starting training for trial 7\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 8\n",
      "Mean loss: 0.42714862794261044, Median loss: 0.4305555555555556, Max loss: 0.5879629629629629\n",
      "Starting training for trial 9\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 10\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 11\n",
      "Mean loss: 0.4266388463264769, Median loss: 0.4305555555555556, Max loss: 0.5578703703703703\n",
      "Starting training for trial 12\n",
      "Mean loss: 0.48798772654811096, Median loss: 0.4652777777777778, Max loss: 0.6782407407407407\n",
      "Starting training for trial 13\n",
      "Mean loss: 0.4266523889121047, Median loss: 0.4305555555555556, Max loss: 0.5810185185185185\n",
      "Starting training for trial 14\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 15\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 16\n",
      "Mean loss: 0.4266465849468357, Median loss: 0.4305555555555556, Max loss: 0.5763888888888888\n",
      "Starting training for trial 17\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 18\n",
      "Mean loss: 0.4293918605191066, Median loss: 0.4305555555555556, Max loss: 0.6018518518518519\n",
      "Starting training for trial 19\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 20\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 21\n",
      "Mean loss: 0.42659434925941403, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 22\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 23\n",
      "Mean loss: 0.42662336908575943, Median loss: 0.4305555555555556, Max loss: 0.5439814814814815\n",
      "Starting training for trial 24\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 25\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 26\n",
      "Mean loss: 0.5278406540681927, Median loss: 0.5509259259259259, Max loss: 0.6736111111111112\n",
      "Starting training for trial 27\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 28\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 29\n",
      "Mean loss: 0.4132229806070174, Median loss: 0.4097222222222222, Max loss: 0.5833333333333334\n",
      "Starting training for trial 30\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 31\n",
      "Mean loss: 0.42884435312872415, Median loss: 0.43287037037037035, Max loss: 0.6666666666666666\n",
      "Starting training for trial 32\n",
      "Mean loss: 0.4278170512760985, Median loss: 0.41435185185185186, Max loss: 0.5972222222222222\n",
      "Starting training for trial 33\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 34\n",
      "Mean loss: 0.5248371020414481, Median loss: 0.5625, Max loss: 0.6851851851851852\n",
      "Starting training for trial 35\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 36\n",
      "Mean loss: 0.5141113742242033, Median loss: 0.5138888888888888, Max loss: 0.6689814814814815\n",
      "Starting training for trial 37\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 38\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 39\n",
      "Mean loss: 0.5027181904010153, Median loss: 0.5138888888888888, Max loss: 0.6574074074074074\n",
      "Starting training for trial 40\n",
      "Mean loss: 0.42595881506245065, Median loss: 0.42824074074074076, Max loss: 0.5787037037037037\n",
      "Starting training for trial 41\n",
      "Mean loss: 0.4251288480289734, Median loss: 0.4305555555555556, Max loss: 0.5601851851851852\n",
      "Starting training for trial 42\n",
      "Mean loss: 0.4294034684496448, Median loss: 0.4375, Max loss: 0.5648148148148148\n",
      "Starting training for trial 43\n",
      "Mean loss: 0.4339054108433549, Median loss: 0.4351851851851852, Max loss: 0.5601851851851852\n",
      "Starting training for trial 44\n",
      "Mean loss: 0.42713121604680315, Median loss: 0.4305555555555556, Max loss: 0.5694444444444444\n",
      "Starting training for trial 45\n",
      "Mean loss: 0.42739529646654595, Median loss: 0.4305555555555556, Max loss: 0.5740740740740741\n",
      "Starting training for trial 46\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 47\n",
      "Mean loss: 0.42728211914379904, Median loss: 0.4305555555555556, Max loss: 0.5787037037037037\n",
      "Starting training for trial 48\n",
      "Mean loss: 0.4278557443778923, Median loss: 0.4305555555555556, Max loss: 0.6805555555555556\n",
      "Starting training for trial 49\n",
      "Mean loss: 0.4300119174753525, Median loss: 0.43287037037037035, Max loss: 0.6018518518518519\n",
      "Starting training for trial 50\n",
      "Mean loss: 0.43287617433563946, Median loss: 0.43287037037037035, Max loss: 0.6574074074074074\n",
      "Starting training for trial 51\n",
      "Mean loss: 0.5542293494915727, Median loss: 0.5601851851851852, Max loss: 0.6782407407407407\n",
      "Starting training for trial 52\n",
      "Mean loss: 0.42662530374084906, Median loss: 0.4305555555555556, Max loss: 0.5462962962962963\n",
      "Starting training for trial 53\n",
      "Mean loss: 0.476044133351906, Median loss: 0.48148148148148145, Max loss: 0.5694444444444444\n",
      "Starting training for trial 54\n",
      "Mean loss: 0.4272782498336197, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 55\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 56\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 57\n",
      "Mean loss: 0.42664368296420113, Median loss: 0.4305555555555556, Max loss: 0.5439814814814815\n",
      "Starting training for trial 58\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 59\n",
      "Mean loss: 0.42661853244803516, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 60\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 61\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 62\n",
      "Mean loss: 0.4266204671031249, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 63\n",
      "Mean loss: 0.42752975499527945, Median loss: 0.4305555555555556, Max loss: 0.5717592592592593\n",
      "Starting training for trial 64\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 65\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 66\n",
      "Mean loss: 0.5733959774651375, Median loss: 0.5694444444444444, Max loss: 0.6828703703703703\n",
      "Starting training for trial 67\n",
      "Mean loss: 0.4267481543390445, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 68\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 69\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 70\n",
      "Mean loss: 0.42781221463837427, Median loss: 0.4305555555555556, Max loss: 0.6759259259259259\n",
      "Starting training for trial 71\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 72\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 73\n",
      "Mean loss: 0.42674621968395476, Median loss: 0.4305555555555556, Max loss: 0.5532407407407407\n",
      "Starting training for trial 74\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 75\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 76\n",
      "Mean loss: 0.4958404915571652, Median loss: 0.5115740740740741, Max loss: 0.6782407407407407\n",
      "Starting training for trial 77\n",
      "Mean loss: 0.42693388122765474, Median loss: 0.4305555555555556, Max loss: 0.625\n",
      "Starting training for trial 78\n",
      "Mean loss: 0.42658564331151044, Median loss: 0.4305555555555556, Max loss: 0.5393518518518519\n",
      "Starting training for trial 79\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Save the best params to file\u001B[39;00m\n\u001B[1;32m      5\u001B[0m best_params \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_params\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    374\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    375\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    382\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    383\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    385\u001B[0m \n\u001B[1;32m    386\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 475\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 63\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 160\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    244\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    246\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    247\u001B[0m ):\n\u001B[0;32m--> 248\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    200\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[0;32mIn[41], line 40\u001B[0m, in \u001B[0;36mobjective\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting training for trial \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrial\u001B[38;5;241m.\u001B[39mnumber\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m---> 40\u001B[0m     \u001B[43mtm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumber_of_examples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m run_evaluation(tm)\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/tmu/models/autoencoder/autoencoder.py:273\u001B[0m, in \u001B[0;36mTMAutoEncoder.fit\u001B[0;34m(self, X, number_of_examples, shuffle, *kwargs)\u001B[0m\n\u001B[1;32m    269\u001B[0m update_clause \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrng\u001B[38;5;241m.\u001B[39mrandom(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumber_of_clauses) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    270\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mclip(average_absolute_weights, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mT)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m class_index:\n\u001B[0;32m--> 273\u001B[0m     Xu, Yu \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclause_bank\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproduce_autoencoder_example\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoded_X\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoded_X_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_true_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_true_probability\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_active\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccumulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccumulation\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m     ta_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_active[i] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m32\u001B[39m\n\u001B[1;32m    281\u001B[0m     chunk_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_active[i] \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m32\u001B[39m\n",
      "File \u001B[0;32m~/Documents/GitHub/uia-master-thesis/.venv/lib/python3.12/site-packages/tmu/clause_bank/clause_bank.py:421\u001B[0m, in \u001B[0;36mClauseBank.produce_autoencoder_example\u001B[0;34m(self, encoded_X, target, target_true_p, accumulation)\u001B[0m\n\u001B[1;32m    417\u001B[0m (X_csr, X_csc, active_output, X) \u001B[38;5;241m=\u001B[39m encoded_X\n\u001B[1;32m    419\u001B[0m target_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrng\u001B[38;5;241m.\u001B[39mrandom() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m target_true_p\n\u001B[0;32m--> 421\u001B[0m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtmu_produce_autoencoder_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mffi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munsigned int *\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactive_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactive_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mffi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munsigned int *\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mascontiguousarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_csr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindptr\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mffi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munsigned int *\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mascontiguousarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_csr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m                                     \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_csr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mffi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munsigned int *\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mascontiguousarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_csc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindptr\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mffi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munsigned int *\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mascontiguousarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_csc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m                                     \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_csc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mffi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munsigned int *\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m                                     \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m                                     \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtarget_value\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m                                     \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43maccumulation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)), target_value\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:52:54.226748Z",
     "start_time": "2025-03-24T00:52:54.223311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "print(best_params)"
   ],
   "id": "704d8ae47917c45f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_clauses': 1037, 'T': 9242, 's': 99, 'max_included_literals': 555, 'accumulation': 1, 'feature_negation': False, 'output_balancing': 0.6877586247267895, 'number_of_examples': 100}\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:52:55.637710Z",
     "start_time": "2025-03-24T00:52:55.634584Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2d8f4fb882ae8aab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "29c4757bdea823da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
