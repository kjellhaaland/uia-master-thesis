{
 "cells": [
  {
   "cell_type": "code",
   "id": "e28183c3-d395-4a3a-8eb4-dba55cb1d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:50.323845Z",
     "start_time": "2025-03-24T02:34:50.302932Z"
    }
   },
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install numpy==1.26.4"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "2b757c20539f2247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:50.335528Z",
     "start_time": "2025-03-24T02:34:50.326614Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from tmu.models.autoencoder.autoencoder import TMAutoEncoder"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:50.361046Z",
     "start_time": "2025-03-24T02:34:50.358251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create folder models if it does not exist\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ],
   "id": "d427f1ccd2f319f8",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "28162fc330bc11f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:50.373737Z",
     "start_time": "2025-03-24T02:34:50.366236Z"
    }
   },
   "source": [
    "def load_train_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_test/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "\n",
    "    # Take a sample of 5000 rows\n",
    "    X = X[:5000]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_labels(farm, event_id):\n",
    "    y = np.loadtxt(f\"./data_test/y_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    y = np.array(y).astype(np.uint32)\n",
    "\n",
    "    # Take a sample of 5000 rows\n",
    "    y = y[:5000]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def load_thresh_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "\n",
    "    # Take the first 5000 rows\n",
    "    X = X[:5000]\n",
    "\n",
    "    return X\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "da4ff95f-ff25-4203-89c8-7e6046e4356b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:50.381391Z",
     "start_time": "2025-03-24T02:34:50.378295Z"
    }
   },
   "source": [
    "def save_model(tm: TMAutoEncoder, filename: str):\n",
    "    a, d = tm.X_train, tm.encoded_X_train\n",
    "\n",
    "    tm.X_train = None\n",
    "    tm.encoded_X_train = None\n",
    "\n",
    "    with open(f\"./models/{filename}\", \"wb\") as f:\n",
    "        pickle.dump(tm, f)\n",
    "\n",
    "    tm.X_train = a\n",
    "    tm.encoded_X_train = d"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:55.371654Z",
     "start_time": "2025-03-24T02:34:50.386357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: Load X_train from a dataset\n",
    "\n",
    "train_datasets = [34, 7, 53, 27, 19, 77, 83, 52, 21, 2, 23, 87, 74, 86, 82]\n",
    "test_dataset = [83, 52]\n",
    "\n",
    "# Load all datasets into one array\n",
    "X_train = np.concatenate([load_train_dataset(\"B\", i) for i in train_datasets])\n",
    "\n",
    "X_test = np.concatenate([load_test_dataset(\"B\", i) for i in test_dataset])\n",
    "y_test = np.concatenate([load_test_labels(\"B\", i) for i in test_dataset])\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ],
   "id": "a31d2f9342f1de77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (704722, 504)\n",
      "X_test shape: (7737, 504)\n",
      "y_test shape: (7737,)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:55.390221Z",
     "start_time": "2025-03-24T02:34:55.387388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hamming_loss(pred, X_test):\n",
    "    \"\"\"\n",
    "    Computes the Hamming loss between predicted and ground truth binary arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - pred (numpy array): Binary predictions of shape (n_samples, n_bits).\n",
    "    - X_test (numpy array): Ground truth binary values of shape (n_samples, n_bits).\n",
    "\n",
    "    Returns:\n",
    "    - float: Hamming loss (fraction of incorrect bits).\n",
    "    \"\"\"\n",
    "    assert pred.shape == X_test.shape, \"Shapes of pred and X_test must match\"\n",
    "\n",
    "    # Compute the number of differing bits\n",
    "    incorrect_bits = np.sum(pred != X_test)\n",
    "\n",
    "    # Total number of bits\n",
    "    total_bits = np.prod(X_test.shape)\n",
    "\n",
    "    # Hamming loss is the fraction of incorrect bits\n",
    "    return incorrect_bits / total_bits"
   ],
   "id": "99456064a07d2ee8",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:34:55.403236Z",
     "start_time": "2025-03-24T02:34:55.395039Z"
    }
   },
   "source": [
    "def run_evaluation(tm: TMAutoEncoder) -> float:\n",
    "    pred = tm.predict(X_test)\n",
    "\n",
    "    loss = [hamming_loss(X_test[i], pred[i]) for i in range(len(X_test))]\n",
    "\n",
    "    print(f\"Mean loss: {np.mean(loss)}, Median loss: {np.median(loss)}, Max loss: {np.max(loss)}\")\n",
    "\n",
    "    # Mean loss for 0s\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    number_of_features = X_train.shape[1]\n",
    "    output_active = np.arange(number_of_features, dtype=np.uint32)\n",
    "\n",
    "    number_of_clauses = trial.suggest_int(\"number_of_clauses\", 20, 2000)\n",
    "    T = trial.suggest_int(\"T\", 20, 10000)\n",
    "    s = trial.suggest_int(\"s\", 1, 100)\n",
    "    max_included_literals = trial.suggest_int(\"max_included_literals\", 1, 3 * number_of_features)\n",
    "    accumulation = trial.suggest_int(\"accumulation\", 1, 10)\n",
    "    feature_negation = trial.suggest_categorical(\"feature_negation\", [True, False])\n",
    "    output_balancing = trial.suggest_float(\"output_balancing\", 0, 10)\n",
    "    number_of_examples = trial.suggest_int(\"number_of_examples\", 100, 100)\n",
    "\n",
    "    tm = TMAutoEncoder(\n",
    "        number_of_clauses=number_of_clauses,\n",
    "        T=T,\n",
    "        s=s,\n",
    "        output_active=output_active,\n",
    "        max_included_literals=max_included_literals,\n",
    "        accumulation=accumulation,\n",
    "        feature_negation=feature_negation,\n",
    "        platform=\"CPU\",  # TODO: Change to CUDA\n",
    "        output_balancing=output_balancing,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for trial {trial.number}\")\n",
    "\n",
    "    for e in range(5):\n",
    "        tm.fit(X_train, number_of_examples=number_of_examples)\n",
    "\n",
    "    # Write the current best result to file \"temp_best.txt\"\n",
    "    with open(\"temp_params.txt\", \"w\") as f:\n",
    "        f.write(f\"Trial: {trial.number}\\n\")\n",
    "\n",
    "    return run_evaluation(tm)\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "d4dc7e4da5c88e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:37:57.943091Z",
     "start_time": "2025-03-24T02:34:55.408300Z"
    }
   },
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "# Save the best params to file\n",
    "best_params = study.best_params\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "with open(\"best_params.txt\", \"w\") as f:\n",
    "    for key, value in best_params.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for trial 0\n",
      "Mean loss: 0.41300563566945886, Median loss: 0.4087301587301587, Max loss: 0.6785714285714286\n",
      "Best params: {'number_of_clauses': 1382, 'T': 5368, 's': 44, 'max_included_literals': 871, 'accumulation': 1, 'feature_negation': True, 'output_balancing': 4.331756938281006, 'number_of_examples': 100}\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T02:37:57.987736Z",
     "start_time": "2025-03-24T02:37:57.984990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "print(best_params)"
   ],
   "id": "704d8ae47917c45f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_clauses': 1382, 'T': 5368, 's': 44, 'max_included_literals': 871, 'accumulation': 1, 'feature_negation': True, 'output_balancing': 4.331756938281006, 'number_of_examples': 100}\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
