{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment description\n",
    "\n",
    "The goal of this notebook is to preprocess all datasets in Wind Farm C to a binary format that can be used for training a TM Classifier."
   ],
   "id": "e85b94674bcffa5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:47:18.227514Z",
     "start_time": "2025-03-22T13:47:18.171048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "a7fa0f63187f7de2",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:47:18.337287Z",
     "start_time": "2025-03-22T13:47:18.238427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wind_farm = \"C\"\n",
    "\n",
    "available_datasets_df = pd.read_csv(f\"../../../data/care_to_compare/Wind Farm {wind_farm}/event_info.csv\",\n",
    "                                    delimiter=';')\n",
    "\n",
    "available_datasets = available_datasets_df[\"event_id\"].values\n",
    "\n",
    "print(available_datasets)\n",
    "\n",
    "train_datasets = available_datasets\n",
    "\n",
    "test_datasets = available_datasets\n"
   ],
   "id": "7de2a6ba82e2aea6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55 81 47 12  4 18 28 39 66 15 78 79 30 33 11 44 49 31 67  9 91  5 90 70\n",
      " 35 16 76  8 85  6 62 36 56 94 54 43 50 64 46 65 61 93 75 41 58 48 88 57\n",
      " 32 89 59 63 80 37 29  1 20 60]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:47:18.382201Z",
     "start_time": "2025-03-22T13:47:18.375676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create folders data_test and data_train if they do not exist\n",
    "os.makedirs(\"data_test\", exist_ok=True)\n",
    "os.makedirs(\"data_train\", exist_ok=True)"
   ],
   "id": "33fcab2e88c188e5",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:47:18.427634Z",
     "start_time": "2025-03-22T13:47:18.410857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exclude_columns = [\"time_stamp\", \"asset_id\", \"id\"]\n",
    "\n",
    "\n",
    "def load_df_and_annotate_anomalies(farm, event_id):\n",
    "    path = f\"../../../data/care_to_compare/Wind Farm {farm}/datasets/{event_id}.csv\"\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "\n",
    "    event_info = pd.read_csv(f\"../../../data/care_to_compare/Wind Farm {farm}/event_info.csv\", delimiter=';')\n",
    "\n",
    "    # Find the row where event_id = event_id\n",
    "    metadata = event_info[event_info['event_id'] == event_id]\n",
    "\n",
    "    event_label = metadata[\"event_label\"].values[0]\n",
    "    event_start_id = metadata[\"event_start_id\"].values[0]\n",
    "    event_end_id = metadata[\"event_end_id\"].values[0]\n",
    "\n",
    "    label_value = 1 if event_label == \"anomaly\" else 0\n",
    "\n",
    "    # All rows where the column \"id\" is between event_start_id and event_end_id\n",
    "    df['label'] = 0\n",
    "    df.loc[(df['id'] >= event_start_id) & (df['id'] <= event_end_id), 'label'] = label_value\n",
    "\n",
    "    # Include all columns except for the ones in exclude_columns\n",
    "    df = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "\n",
    "    # Remove columns with suffixes in exclude_columns_with_suffix\n",
    "    df = df[[col for col in df.columns if not col.endswith('_max')]]\n",
    "    df = df[[col for col in df.columns if not col.endswith('_min')]]\n",
    "    df = df[[col for col in df.columns if not col.endswith('_std')]]\n",
    "\n",
    "    return df"
   ],
   "id": "890df7a6f9bbbd18",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:47:18.435929Z",
     "start_time": "2025-03-22T13:47:18.431557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_min_max(farm, dataset_ids):\n",
    "    # For each column get the min and max value\n",
    "    min_max_values = {}\n",
    "\n",
    "    for dataset_id in dataset_ids:\n",
    "        df = load_df_and_annotate_anomalies(farm, dataset_id)\n",
    "\n",
    "        for col in df.columns:\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "\n",
    "            if col not in min_max_values:\n",
    "                min_max_values[col] = (min_val, max_val)\n",
    "            else:\n",
    "                current_min, current_max = min_max_values[col]\n",
    "                min_max_values[col] = (min(min_val, current_min), max(max_val, current_max))\n",
    "\n",
    "    return min_max_values"
   ],
   "id": "a044eef9e1b7a0f8",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:47:18.451702Z",
     "start_time": "2025-03-22T13:47:18.444949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_to_bit_integers(df, minmax, bits_per_column=8):\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    for col in df.columns:\n",
    "        min_val = minmax[col][0]\n",
    "        max_val = minmax[col][1]\n",
    "\n",
    "        shifted = normalized_df[col] - min_val + 1\n",
    "        log_data = np.log1p(shifted)\n",
    "\n",
    "        global_log_min = np.log1p(1)  # log1p(1) because shift guarantees min = 1\n",
    "        global_log_max = np.log1p(max_val - min_val + 1)  # Max in transformed space\n",
    "\n",
    "        normalized_df[col] = (log_data - global_log_min) / (global_log_max - global_log_min) * (\n",
    "                (2 ** bits_per_column) - 1)\n",
    "\n",
    "    # Convert the normalized values to integers\n",
    "    int_df = normalized_df.astype(int)\n",
    "\n",
    "    # Flatten each row into an array of 10-bit integers\n",
    "    int_arrays = int_df.apply(lambda row: row.values.flatten(), axis=1).tolist()\n",
    "\n",
    "    # Represent each cell as a 10-bit integer string\n",
    "    bin_arrays = [[f\"{cell:0{bits_per_column}b}\" for cell in row] for row in int_arrays]\n",
    "\n",
    "    # Split each 10-bit integer string into individual integers for each row\n",
    "    # preserve the columns of bin_arrays\n",
    "    bin_int_arrays = [[int(cell) for cell in list(''.join(row))] for row in bin_arrays]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    int_arrays = np.array(bin_int_arrays)\n",
    "\n",
    "    return int_arrays"
   ],
   "id": "383106dfae1e5bf4",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:47:18.472133Z",
     "start_time": "2025-03-22T13:47:18.461679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binarize_dataset_for_training(farm, event_id, output_path, min_max_values, bits_per_column=8):\n",
    "    # Load original dataset from file\n",
    "    df = load_df_and_annotate_anomalies(farm, event_id)\n",
    "    df = df[df['train_test'] == 'train']\n",
    "\n",
    "    # Remove all rows where status_type_id is not 0 or 2\n",
    "    df = df[df['status_type_id'].isin([0, 2])]\n",
    "\n",
    "    # Take 1000 random samples\n",
    "    df = df.sample(n=4000)\n",
    "\n",
    "    # Split into data and labels\n",
    "    X_values = df.drop(columns=['label', 'train_test', 'status_type_id'])\n",
    "    y_values = df['label']\n",
    "\n",
    "    X_values = X_values.apply(pd.to_numeric, errors='coerce')\n",
    "    X_values = X_values.dropna(axis=1)\n",
    "\n",
    "    # Print number of columns\n",
    "    print(f\"Number of features: {len(X_values.columns)}\")\n",
    "\n",
    "    X_values_bin = convert_to_bit_integers(X_values, min_max_values, bits_per_column).astype(np.uint32)\n",
    "    y_values_bin = y_values.values.astype(np.uint32)\n",
    "\n",
    "    print(f\"Number of columns: {X_values_bin.shape[1]}\")\n",
    "\n",
    "    # Output to file using np\n",
    "    np.savetxt(f\"{output_path}/X_{farm}_{event_id}.txt\", X_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/y_{farm}_{event_id}.txt\", y_values_bin, fmt='%d')\n",
    "\n",
    "    num_1s = np.count_nonzero(y_values_bin == 1)\n",
    "    num_0s = np.count_nonzero(y_values_bin == 0)\n",
    "\n",
    "    print(f\"Saved {event_id} to {output_path}\")\n",
    "    print(f\"Number of 1s: {num_1s}, Number of 0s: {num_0s}\")\n",
    "\n",
    "\n",
    "def binarize_dataset_for_testing(farm, event_id, output_path, min_max_values, bits_per_column=8):\n",
    "    # Load original dataset from file\n",
    "    df = load_df_and_annotate_anomalies(farm, event_id)\n",
    "\n",
    "    df = df[df['train_test'] == 'prediction']\n",
    "\n",
    "    # Split into data and labels\n",
    "    X_values = df.drop(columns=['label', 'train_test', 'status_type_id'])\n",
    "    y_values = df['label']\n",
    "    z_values = df['status_type_id']\n",
    "\n",
    "    X_values = X_values.apply(pd.to_numeric, errors='coerce')\n",
    "    X_values = X_values.dropna(axis=1)\n",
    "\n",
    "    # Print number of columns\n",
    "    print(f\"Number of features: {len(X_values.columns)}\")\n",
    "\n",
    "    X_values_bin = convert_to_bit_integers(X_values, min_max_values, bits_per_column).astype(np.uint32)\n",
    "    y_values_bin = y_values.values.astype(np.uint32)\n",
    "    z_valued_bin = z_values.values.astype(np.uint32)\n",
    "\n",
    "    print(f\"Number of columns: {X_values_bin.shape[1]}\")\n",
    "\n",
    "    # Output to file using np\n",
    "    np.savetxt(f\"{output_path}/X_{farm}_{event_id}.txt\", X_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/y_{farm}_{event_id}.txt\", y_values_bin, fmt='%d')\n",
    "    np.savetxt(f\"{output_path}/z_{farm}_{event_id}.txt\", z_valued_bin, fmt='%d')\n",
    "\n",
    "    num_1s = np.count_nonzero(y_values_bin == 1)\n",
    "    num_0s = np.count_nonzero(y_values_bin == 0)\n",
    "\n",
    "    print(f\"Saved {event_id} to {output_path}\")\n",
    "    print(f\"Number of 1s: {num_1s}, Number of 0s: {num_0s}\")"
   ],
   "id": "67a9eb610d672ee3",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:50:16.446102Z",
     "start_time": "2025-03-22T13:47:18.490661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_max_values_dict = calculate_min_max(wind_farm, test_datasets)\n",
    "\n",
    "# Save to file\n",
    "with open(\"min_max_values.txt\", \"w\") as f:\n",
    "    for key, value in min_max_values_dict.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "id": "b140f91bb2a74030",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:50:16.482812Z",
     "start_time": "2025-03-22T13:50:16.479999Z"
    }
   },
   "cell_type": "code",
   "source": "bits = 5",
   "id": "a824517b052b4a92",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:54:11.733088Z",
     "start_time": "2025-03-22T13:50:16.536518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in train_datasets:\n",
    "    binarize_dataset_for_training(wind_farm, dataset, \"./data_train\", min_max_values_dict, bits)"
   ],
   "id": "31e31942920e7e0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 55 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 81 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 47 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 12 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 4 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 18 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 28 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 39 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 66 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 15 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 78 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 79 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 30 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 33 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 11 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 44 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 49 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 31 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 67 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 9 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 91 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 5 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 90 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 70 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 35 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 16 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 76 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 8 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 85 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 6 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 62 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 30\n",
      "Number of columns: 150\n",
      "Saved 36 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 56 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 94 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 54 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 43 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 50 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 64 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 46 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 65 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 61 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 93 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 75 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 41 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 58 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 48 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 88 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 57 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 32 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 89 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 59 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 63 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 80 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 37 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 29 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 1 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 20 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 60 to ./data_train\n",
      "Number of 1s: 0, Number of 0s: 4000\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T13:57:27.808168Z",
     "start_time": "2025-03-22T13:54:11.768065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset in test_datasets:\n",
    "    binarize_dataset_for_testing(wind_farm, dataset, \"./data_test\", min_max_values_dict, bits)"
   ],
   "id": "e879c62b0a552f43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 55 to ./data_test\n",
      "Number of 1s: 2473, Number of 0s: 720\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 81 to ./data_test\n",
      "Number of 1s: 364, Number of 0s: 1008\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 47 to ./data_test\n",
      "Number of 1s: 713, Number of 0s: 864\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 12 to ./data_test\n",
      "Number of 1s: 3259, Number of 0s: 288\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 4 to ./data_test\n",
      "Number of 1s: 2737, Number of 0s: 1152\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 18 to ./data_test\n",
      "Number of 1s: 576, Number of 0s: 1152\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 28 to ./data_test\n",
      "Number of 1s: 2926, Number of 0s: 432\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 39 to ./data_test\n",
      "Number of 1s: 735, Number of 0s: 432\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 66 to ./data_test\n",
      "Number of 1s: 943, Number of 0s: 864\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 15 to ./data_test\n",
      "Number of 1s: 2449, Number of 0s: 288\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 78 to ./data_test\n",
      "Number of 1s: 298, Number of 0s: 288\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 79 to ./data_test\n",
      "Number of 1s: 289, Number of 0s: 432\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 30 to ./data_test\n",
      "Number of 1s: 3263, Number of 0s: 288\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 33 to ./data_test\n",
      "Number of 1s: 2881, Number of 0s: 432\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 11 to ./data_test\n",
      "Number of 1s: 3157, Number of 0s: 864\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 44 to ./data_test\n",
      "Number of 1s: 9435, Number of 0s: 1008\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 49 to ./data_test\n",
      "Number of 1s: 598, Number of 0s: 1008\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 31 to ./data_test\n",
      "Number of 1s: 1021, Number of 0s: 1008\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 67 to ./data_test\n",
      "Number of 1s: 8353, Number of 0s: 576\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 9 to ./data_test\n",
      "Number of 1s: 3037, Number of 0s: 432\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 91 to ./data_test\n",
      "Number of 1s: 2896, Number of 0s: 1152\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 5 to ./data_test\n",
      "Number of 1s: 523, Number of 0s: 144\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 90 to ./data_test\n",
      "Number of 1s: 1744, Number of 0s: 576\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 70 to ./data_test\n",
      "Number of 1s: 2902, Number of 0s: 576\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 35 to ./data_test\n",
      "Number of 1s: 919, Number of 0s: 288\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 16 to ./data_test\n",
      "Number of 1s: 2160, Number of 0s: 144\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 76 to ./data_test\n",
      "Number of 1s: 246, Number of 0s: 576\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 8 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2242\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 85 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 1585\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 6 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2305\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 62 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 1032\n",
      "Number of features: 148\n",
      "Number of columns: 740\n",
      "Saved 36 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2888\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 56 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2296\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 94 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2737\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 54 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 3025\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 43 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2593\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 50 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 3457\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 64 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 1873\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 46 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2573\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 65 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 3358\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 61 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 3025\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 93 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 3313\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 75 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 3601\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 41 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 4258\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 58 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 1873\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 48 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2737\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 88 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2881\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 57 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2449\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 32 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2449\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 89 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2737\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 59 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2737\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 63 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2305\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 80 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2353\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 37 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2449\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 29 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2305\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 1 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2161\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 20 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2593\n",
      "Number of features: 238\n",
      "Number of columns: 1190\n",
      "Saved 60 to ./data_test\n",
      "Number of 1s: 0, Number of 0s: 2449\n"
     ]
    }
   ],
   "execution_count": 61
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
