{
 "cells": [
  {
   "cell_type": "code",
   "id": "e28183c3-d395-4a3a-8eb4-dba55cb1d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:20:59.980182Z",
     "start_time": "2025-04-01T13:20:59.963416Z"
    }
   },
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install numpy==1.26.4"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "2b757c20539f2247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:20:59.992786Z",
     "start_time": "2025-04-01T13:20:59.990102Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tmu.models.autoencoder.autoencoder import TMAutoEncoder"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:00.007723Z",
     "start_time": "2025-04-01T13:21:00.005011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create folder models if it does not exist\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ],
   "id": "30305fc8025f45c1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "28162fc330bc11f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:00.022382Z",
     "start_time": "2025-04-01T13:21:00.017879Z"
    }
   },
   "source": [
    "def load_train_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "da4ff95f-ff25-4203-89c8-7e6046e4356b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:00.038728Z",
     "start_time": "2025-04-01T13:21:00.035191Z"
    }
   },
   "source": [
    "def save_model(tm: TMAutoEncoder, filename: str):\n",
    "    a, d = tm.X_train, tm.encoded_X_train\n",
    "\n",
    "    tm.X_train = None\n",
    "    tm.encoded_X_train = None\n",
    "\n",
    "    with open(f\"./models/{filename}\", \"wb\") as f:\n",
    "        pickle.dump(tm, f)\n",
    "\n",
    "    tm.X_train = a\n",
    "    tm.encoded_X_train = d"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:02.295527Z",
     "start_time": "2025-04-01T13:21:00.047780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datasets = [34, 7, 53, 27, 19, 77, 83, 52, 21, 2, 23, 87, 74, 86, 82]\n",
    "test_dataset = [52]\n",
    "\n",
    "X_train = np.concatenate([load_train_dataset(\"B\", i) for i in train_datasets])\n",
    "\n",
    "X_test = np.concatenate([load_train_dataset(\"B\", i) for i in test_dataset])\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ],
   "id": "a31d2f9342f1de77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (704714, 189)\n",
      "X_test shape: (43994, 189)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:02.306379Z",
     "start_time": "2025-04-01T13:21:02.303721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hamming_loss(pred, X_test):\n",
    "    \"\"\"\n",
    "    Computes the Hamming loss between predicted and ground truth binary arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - pred (numpy array): Binary predictions of shape (n_samples, n_bits).\n",
    "    - X_test (numpy array): Ground truth binary values of shape (n_samples, n_bits).\n",
    "\n",
    "    Returns:\n",
    "    - float: Hamming loss (fraction of incorrect bits).\n",
    "    \"\"\"\n",
    "    assert pred.shape == X_test.shape, \"Shapes of pred and X_test must match\"\n",
    "\n",
    "    # Compute the number of differing bits\n",
    "    incorrect_bits = np.sum(pred != X_test)\n",
    "\n",
    "    # Total number of bits\n",
    "    total_bits = np.prod(X_test.shape)\n",
    "\n",
    "    # Hamming loss is the fraction of incorrect bits\n",
    "    return incorrect_bits / total_bits"
   ],
   "id": "6188dfae59ac0259",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:02.314336Z",
     "start_time": "2025-04-01T13:21:02.312238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(tm, X):\n",
    "    pred = tm.predict(X)\n",
    "\n",
    "    loss = [hamming_loss(X[i], pred[i]) for i in range(len(X))]\n",
    "\n",
    "    return np.mean(loss), np.median(loss), np.max(loss), np.min(loss)"
   ],
   "id": "8b4cf0985093a6bd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:02.321515Z",
     "start_time": "2025-04-01T13:21:02.319060Z"
    }
   },
   "source": [
    "def train(args):\n",
    "    tm = TMAutoEncoder(\n",
    "        number_of_clauses=args[\"num_clauses\"],\n",
    "        T=args[\"T\"],\n",
    "        s=args[\"s\"],\n",
    "        output_active=args[\"output_active\"],\n",
    "        max_included_literals=args[\"max_included_literals\"],\n",
    "        accumulation=args[\"accumulation\"],\n",
    "        feature_negation=args[\"feature_negation\"],\n",
    "        platform=args[\"platform\"],\n",
    "        output_balancing=args[\"output_balancing\"],\n",
    "        boost_true_positive_feedback=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for {args['epochs']} epochs\")\n",
    "\n",
    "    for e in range(args[\"epochs\"]):\n",
    "        tm.fit(X_train, number_of_examples=args[\"number_of_examples\"])\n",
    "\n",
    "        lmean, lmed, lmax, lmin = test(tm, X_test)\n",
    "        print(f\"Epoch: {e + 1} Mean loss: {lmean:4f}, Median loss: {lmed:4f}, Max loss: {lmax:4f}, Min loss: {lmin:4f}\")\n",
    "\n",
    "        save_model(tm, f\"latest_{e}.pkl\")\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:21:02.331189Z",
     "start_time": "2025-04-01T13:21:02.329381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_features = X_train.shape[1]\n",
    "output_active = np.arange(number_of_features, dtype=np.uint32)\n",
    "\n",
    "print(f\"Number of features {number_of_features}\")"
   ],
   "id": "e39fbba456bd25dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 189\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "d4dc7e4da5c88e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:48:27.214505Z",
     "start_time": "2025-04-01T13:21:02.417752Z"
    }
   },
   "source": [
    "number_of_clauses = 4140\n",
    "\n",
    "args: dict = {\n",
    "    \"number_of_examples\": 100,\n",
    "    \"output_active\": output_active,\n",
    "    \"accumulation\": 1,\n",
    "    \"num_clauses\": number_of_clauses,\n",
    "    \"T\": 965,\n",
    "    \"s\": 25.0,\n",
    "    \"epochs\": 50,\n",
    "    \"platform\": \"CPU\",\n",
    "    \"output_balancing\": 0,\n",
    "    \"max_included_literals\": 332,\n",
    "    \"feature_negation\": False,\n",
    "}\n",
    "\n",
    "result = train(args)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 50 epochs\n",
      "Epoch: 1 Mean loss: 0.106839, Median loss: 0.100529, Max loss: 0.656085, Min loss: 0.010582\n",
      "Epoch: 2 Mean loss: 0.078335, Median loss: 0.068783, Max loss: 0.370370, Min loss: 0.005291\n",
      "Epoch: 3 Mean loss: 0.063585, Median loss: 0.058201, Max loss: 0.296296, Min loss: 0.005291\n",
      "Epoch: 4 Mean loss: 0.052908, Median loss: 0.047619, Max loss: 0.269841, Min loss: 0.005291\n",
      "Epoch: 5 Mean loss: 0.046744, Median loss: 0.042328, Max loss: 0.291005, Min loss: 0.000000\n",
      "Epoch: 6 Mean loss: 0.041526, Median loss: 0.037037, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 7 Mean loss: 0.037146, Median loss: 0.031746, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 8 Mean loss: 0.034449, Median loss: 0.031746, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 9 Mean loss: 0.032808, Median loss: 0.026455, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 10 Mean loss: 0.030029, Median loss: 0.026455, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 11 Mean loss: 0.028487, Median loss: 0.021164, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 12 Mean loss: 0.027421, Median loss: 0.021164, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 13 Mean loss: 0.024909, Median loss: 0.021164, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 14 Mean loss: 0.024509, Median loss: 0.021164, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 15 Mean loss: 0.023655, Median loss: 0.015873, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 16 Mean loss: 0.022746, Median loss: 0.015873, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 17 Mean loss: 0.022036, Median loss: 0.015873, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 18 Mean loss: 0.021235, Median loss: 0.015873, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 19 Mean loss: 0.020552, Median loss: 0.015873, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 20 Mean loss: 0.019562, Median loss: 0.015873, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 21 Mean loss: 0.019160, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 22 Mean loss: 0.019146, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 23 Mean loss: 0.018851, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 24 Mean loss: 0.018624, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 25 Mean loss: 0.018241, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 26 Mean loss: 0.016875, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 27 Mean loss: 0.017092, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 28 Mean loss: 0.016263, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 29 Mean loss: 0.016569, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 30 Mean loss: 0.016919, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 31 Mean loss: 0.016342, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 32 Mean loss: 0.016538, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 33 Mean loss: 0.015110, Median loss: 0.010582, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 34 Mean loss: 0.014374, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 35 Mean loss: 0.014946, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 36 Mean loss: 0.015131, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 37 Mean loss: 0.013426, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 38 Mean loss: 0.014051, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 39 Mean loss: 0.014385, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 40 Mean loss: 0.013906, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 41 Mean loss: 0.013470, Median loss: 0.005291, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 42 Mean loss: 0.013762, Median loss: 0.010582, Max loss: 0.740741, Min loss: 0.000000\n",
      "Epoch: 43 Mean loss: 0.013708, Median loss: 0.010582, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 44 Mean loss: 0.012402, Median loss: 0.010582, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 45 Mean loss: 0.012354, Median loss: 0.005291, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 46 Mean loss: 0.012166, Median loss: 0.005291, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 47 Mean loss: 0.012202, Median loss: 0.005291, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 48 Mean loss: 0.011905, Median loss: 0.005291, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 49 Mean loss: 0.011750, Median loss: 0.005291, Max loss: 0.735450, Min loss: 0.000000\n",
      "Epoch: 50 Mean loss: 0.011594, Median loss: 0.005291, Max loss: 0.735450, Min loss: 0.000000\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
