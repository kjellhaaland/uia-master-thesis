{
 "cells": [
  {
   "cell_type": "code",
   "id": "e28183c3-d395-4a3a-8eb4-dba55cb1d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:55.060196Z",
     "start_time": "2025-03-31T16:49:55.056572Z"
    }
   },
   "source": [
    "#%pip install git+https://github.com/cair/tmu.git\n",
    "#%pip install numpy==1.26.4"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "2b757c20539f2247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:55.067409Z",
     "start_time": "2025-03-31T16:49:55.064703Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from tmu.models.autoencoder.autoencoder import TMAutoEncoder"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:55.079815Z",
     "start_time": "2025-03-31T16:49:55.076807Z"
    }
   },
   "cell_type": "code",
   "source": "bits = 8",
   "id": "6e9419e495350303",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:55.096919Z",
     "start_time": "2025-03-31T16:49:55.090701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create folder models if it does not exist\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ],
   "id": "d427f1ccd2f319f8",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "28162fc330bc11f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:55.108155Z",
     "start_time": "2025-03-31T16:49:55.104491Z"
    }
   },
   "source": [
    "def load_train_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_test/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "\n",
    "    # Take a sample of 5000 rows\n",
    "    X = X[:5000]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_test_labels(farm, event_id):\n",
    "    # Load dataframe from file\n",
    "    df = pd.read_csv(f\"./data_test/y_{farm}_{event_id}.csv\")\n",
    "\n",
    "    labels = df['label'].values\n",
    "    status_ids = df['status_type_id'].values\n",
    "    train_test = df['train_test'].values\n",
    "\n",
    "    # Take the first 3000 rows\n",
    "    labels = labels[-10000:]\n",
    "    status_ids = status_ids[-10000:]\n",
    "    train_test = train_test[-10000:]\n",
    "\n",
    "    return np.array(labels).astype(np.uint32), np.array(status_ids).astype(np.uint32), train_test\n",
    "\n",
    "\n",
    "def load_thresh_dataset(farm, event_id):\n",
    "    X = np.loadtxt(f\"./data_train/X_{farm}_{event_id}.txt\", dtype=np.uint32)\n",
    "    X = np.array(X).astype(np.uint32)\n",
    "\n",
    "    # Take the first 5000 rows\n",
    "    X = X[:5000]\n",
    "\n",
    "    return X\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "da4ff95f-ff25-4203-89c8-7e6046e4356b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:55.117146Z",
     "start_time": "2025-03-31T16:49:55.114231Z"
    }
   },
   "source": [
    "def save_model(tm: TMAutoEncoder, filename: str):\n",
    "    a, d = tm.X_train, tm.encoded_X_train\n",
    "\n",
    "    tm.X_train = None\n",
    "    tm.encoded_X_train = None\n",
    "\n",
    "    with open(f\"./models/{filename}\", \"wb\") as f:\n",
    "        pickle.dump(tm, f)\n",
    "\n",
    "    tm.X_train = a\n",
    "    tm.encoded_X_train = d"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:56.583684Z",
     "start_time": "2025-03-31T16:49:55.128122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datasets = [34, 7, ]  # 53, 27, 19, 77, 83, 52, 21, 2, 23, 87, 74, 86, 82]\n",
    "\n",
    "# Load all datasets into one array\n",
    "X_train = np.concatenate([load_train_dataset(\"B\", i) for i in train_datasets])\n",
    "\n",
    "X_test = load_test_dataset(\"B\", 52)\n",
    "y_test, status_ids, train_test = load_test_labels(\"B\", 52)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ],
   "id": "a31d2f9342f1de77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (93206, 504)\n",
      "X_test shape: (5000, 504)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:56.661093Z",
     "start_time": "2025-03-31T16:49:56.657460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_to_decimal(arr, bit_length):\n",
    "    # Split the array into chunks of bit_length\n",
    "    numbers = [int(\"\".join(map(str, arr[i:i + bit_length])), 2) for i in range(0, len(arr), bit_length)]\n",
    "    return numbers\n",
    "\n",
    "\n",
    "def huber_loss(pred, X_test, delta=1.0):\n",
    "    # Reconstruct the original values (5 bits)\n",
    "    p = binary_to_decimal(pred, bits)\n",
    "    x = binary_to_decimal(X_test, bits)\n",
    "\n",
    "    # Compute the Huber loss\n",
    "    loss = np.where(np.abs(np.array(p) - np.array(x)) < delta, 0.5 * ((np.array(p) - np.array(x)) ** 2),\n",
    "                    delta * (np.abs(np.array(p) - np.array(x)) - 0.5 * delta))\n",
    "\n",
    "    return np.mean(loss)"
   ],
   "id": "99456064a07d2ee8",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:49:56.691151Z",
     "start_time": "2025-03-31T16:49:56.682545Z"
    }
   },
   "source": [
    "def run_evaluation(tm: TMAutoEncoder) -> float:\n",
    "    pred = tm.predict(X_test)\n",
    "\n",
    "    loss = [huber_loss(X_test[i], pred[i]) for i in range(len(X_test))]\n",
    "\n",
    "    print(f\"Mean loss: {np.mean(loss)}, Median loss: {np.median(loss)}, Max loss: {np.max(loss)}\")\n",
    "\n",
    "    # Mean loss for 0s\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    number_of_features = X_train.shape[1]\n",
    "    output_active = np.arange(number_of_features, dtype=np.uint32)\n",
    "\n",
    "    number_of_clauses = trial.suggest_int(\"number_of_clauses\", 20, 2000)\n",
    "    T = trial.suggest_int(\"T\", 20, 10000)\n",
    "    max_included_literals = trial.suggest_int(\"max_included_literals\", 1, 3 * number_of_features)\n",
    "\n",
    "    tm = TMAutoEncoder(\n",
    "        number_of_clauses=number_of_clauses,\n",
    "        T=T,\n",
    "        s=25.0,\n",
    "        output_active=output_active,\n",
    "        max_included_literals=max_included_literals,\n",
    "        accumulation=1,\n",
    "        feature_negation=False,\n",
    "        platform=\"CPU\",  # TODO: Change to CUDA\n",
    "        output_balancing=0,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting training for trial {trial.number}\")\n",
    "\n",
    "    for e in range(5):\n",
    "        tm.fit(X_train, number_of_examples=100)\n",
    "\n",
    "    # Write the current best result to file \"temp_best.txt\"\n",
    "    with open(\"temp_params.txt\", \"w\") as f:\n",
    "        f.write(f\"Trial: {trial.number}\\n\")\n",
    "\n",
    "    return run_evaluation(tm)\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "d4dc7e4da5c88e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:51:13.307951Z",
     "start_time": "2025-03-31T16:49:56.707837Z"
    }
   },
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "# Save the best params to file\n",
    "best_params = study.best_params\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "with open(\"best_params.txt\", \"w\") as f:\n",
    "    for key, value in best_params.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for trial 0\n",
      "Mean loss: 17.39273015873016, Median loss: 13.96031746031746, Max loss: 162.38888888888889\n",
      "Best params: {'number_of_clauses': 930, 'T': 4185, 'max_included_literals': 115}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:51:13.372515Z",
     "start_time": "2025-03-31T16:51:13.366517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "print(best_params)"
   ],
   "id": "704d8ae47917c45f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_clauses': 930, 'T': 4185, 'max_included_literals': 115}\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
